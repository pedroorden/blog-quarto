[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Estudié Sociología en la UBA, actualmente coordino el NIS, formo parte de. equipo análisis e investigación sobre inteligencia artificial en la UNVM y trabajo con investigador asociado en diversas instituciones públicas y privadas.\nComo sociólogo-científico de datos busco resolver preguntas sociológicas complégicas con la técnica contemporánea, combinando los saberes propios de la estadística y la programación con la epistemología y la hermenéutica de las ciencias sociales.\nSi te interesa lo que hago y crees que puede ser valioso que conversemos, no dudes en escribirme!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tecnología y Sociedad",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n10 min\n\n\n\ncodigo\n\n\ntutorial\n\n\n\n\nNov 2, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10 min\n\n\n\ncodigo\n\n\nanalisis\n\n\ntutorial\n\n\n\n\nOct 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7 min\n\n\n\ncodigo\n\n\nanalisis\n\n\nvideo\n\n\ntutorial\n\n\n\n\nOct 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9 min\n\n\n\nvisualizaciones\n\n\ncodigo\n\n\n\n\nSep 24, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n11 min\n\n\n\ncodigo\n\n\napuntes\n\n\n\n\nSep 14, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n13 min\n\n\n\ncodigo\n\n\nanalisis\n\n\nvideo\n\n\ntutorial\n\n\n\n\nSep 6, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0 min\n\n\n\neditorial\n\n\n\n\nSep 1, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/abuelos/index.html",
    "href": "posts/abuelos/index.html",
    "title": "Situaciones de pobreza por ingreso en adultos mayores",
    "section": "",
    "text": "La crisis de ingresos, que sobrevino a la pospandemia y al acuerdo de deuda con el Fondo Monetario Internacional, ha tenido un impacto profundo en las condiciones de vida de los argentinos y argentinas1.\nEn el caso de la pobreza, como en otros períodos históricos de crisis social y económica, pasó de ser un problema exclusivo de aquellas personas con dificultades para obtener un puesto de trabajo o en condiciones de marginación social, para alcanzar a otros sectores sociales tradicionalmente incluidos como los ocupados2, siendo incluso muchos de ellos empleados del sector formal de la economía, o bien sectores de jubilados; que aún cobrando un haber previsional, producto del trabajo de su vida, no alcanzan a cubrir sus necesidades básicas esenciales.\nDicho lo cual, la propuesta aquí será explorar la realidad de este segundo grupo, muchas veces invisibilizado negado por la sociedad y las academias universitarias: los jubilados. Pondremos nuestra atención particularmente en el subgrupo que cobra el haber mínimo y que representa, según ANSES3, aproximadamente el 50% del segmento de pasivos en Argentina. Operativamente, se buscará conocer a lo largo de los últimos 10 años cómo han evolucionado las jubilaciones mínimas en nuestro país, y en qué medida han alcanzado, o no, a cubrir la canasta básica específica calculada por la Defensoría del Pueblo de la Tercera Edad de la Ciudad de Buenos Aires.\nFinalmente, se procurará aportar nuevos elementos para pensar el proceso empobrecimiento de este colectivo por ingresos."
  },
  {
    "objectID": "posts/abuelos/index.html#recopilación-de-datos-y-fuentes",
    "href": "posts/abuelos/index.html#recopilación-de-datos-y-fuentes",
    "title": "Situaciones de pobreza por ingreso en adultos mayores",
    "section": "Recopilación de datos y fuentes",
    "text": "Recopilación de datos y fuentes\nPara explorar los datos de ingresos de los jubilados se consultará del portal de datos abiertos del Estado Nacional el repositorio del haber mínimo jubilatorio, mensual, en pesos corrientes desde 1971, a cargo de la Subsecretaría de Programación Macroeconómica de la Nación.\nLos valores de costo de vida se analizan en función de la denominada “Canasta De Los Jubilados”, una estimación complementaria a las oficiales, desarrollada por la Defensoría del Pueblo de la Tercera Edad de la Ciudad de Buenos Aires . Los datos fueron recuperados de la web por medio de una técnica simple de escrapeo y se encuentran disponibilizados github.\nPor medio del cruce de ambos conjuntos de datos se pretende aportar nuevas claves para estimar en qué medida el colectivo de adultos mayores que cobra el haber mínimo previsional puede garantizar para sí una canasta adecuada a sus necesidades reales."
  },
  {
    "objectID": "posts/abuelos/index.html#librerías",
    "href": "posts/abuelos/index.html#librerías",
    "title": "Situaciones de pobreza por ingreso en adultos mayores",
    "section": "Librerías",
    "text": "Librerías\nPara comenzar se requerirán las librerías tidyverse y lubridate necesarias para los procesamientos que siguen a continuación."
  },
  {
    "objectID": "posts/abuelos/index.html#carga-de-datasets-y-primera-aproximación-a-los-datos",
    "href": "posts/abuelos/index.html#carga-de-datasets-y-primera-aproximación-a-los-datos",
    "title": "Situaciones de pobreza por ingreso en adultos mayores",
    "section": "Carga de datasets y primera aproximación a los datos",
    "text": "Carga de datasets y primera aproximación a los datos\nSe cargan los conjuntos de datos jubilación y canasta.\nEn ambos casos se trata de archivos formato csv, levantados en R con la función read.csv().\n\n\nVer código\n#datos de haberes minimos\njubilacion <- read.csv(\"https://infra.datos.gob.ar/catalog/sspm/dataset/58/distribution/58.1/download/haber-minimo-jubilatorio-pesos-corrientes-valores-mensuales-desde-1971.csv\")\n\ncanasta <- read.csv(\"https://raw.githubusercontent.com/pedroorden/canasta-jubilados/main/canasta.csv\")\n\n\nDado que el Estado Nacional generalmente plantea demoras significativas en la actualización de datos abiertos, agregamos manualmente el valor de jubilación para octubre de 2022.\n\n\nVer código\njubilacion<-jubilacion%>%\n  select(indice_tiempo, mensual_pesos)\n\njubilacion[nrow(jubilacion) + 1,] <- c( \"2022-10-01\", 50353)\n\njubilacion<-jubilacion%>%\n  mutate(mensual_pesos=as.numeric(mensual_pesos))\n\n\njubilacion contiene, como mencionamos anteriormente, los valores históricos del haber mínimo desde 1971 en Argentina . De aquí se seleccionan las columnas indice_tiempo y mensual_pesos, con datos de fecha y valor del haber respectivamente.\n\n\nVer código\ncanasta <- canasta%>%\n  select(!X)\n\n\nPor su parte, el conjunto de datos canasta recupera los valores de la canasta de los jubilados desde 2010 a la fecha y se compone de una variable de tiempo (indice_tiempo) y otra propia de su valorización neta (valor.canasta). Se descarta la variable X que numera las filas."
  },
  {
    "objectID": "posts/abuelos/index.html#transformación-de-datos",
    "href": "posts/abuelos/index.html#transformación-de-datos",
    "title": "Situaciones de pobreza por ingreso en adultos mayores",
    "section": "Transformación de datos",
    "text": "Transformación de datos\ncanasta y jubilacion serán combinados vía la función left_join() en un nuevo dataframe llamado datosjub, que contiene las variables originales, y crea la variable ncanasta que divide por mes el valor de la canasta de los jubilados por el monto mensual de los haberes, generando el dato de cuántas jubilaciones mínimas son necesarias para cubrir el costo de vida real de un jubilado desde 2010 a la fecha.\nSeguidamente se renombran variables por un tema de practicidad y se transforma la columna fecha en formato temporal.\n\n\nVer código\ndatosjub <- canasta%>%\n  left_join(jubilacion, by=\"indice_tiempo\")%>%\n  mutate(ncanasta=valor.canasta/mensual_pesos)%>%\n  rename(fecha=indice_tiempo,\n         canasta=valor.canasta,\n         haber_minimo=mensual_pesos)%>%\n  mutate(fecha=as_date(fecha))%>%\n  mutate_if(is.numeric, round, digits=2)\n\n\n\nImportante: la decisión de hacer el join a partir del df canasta (y no del dataset jubilación) tiene que ver con la posibilidad de establecer la línea de tiempo de referencia del análisis a partir de las observaciones parcialmente continuas que supone el proceso de medición de la canasta de los jubilados."
  },
  {
    "objectID": "posts/abuelos/index.html#visualización",
    "href": "posts/abuelos/index.html#visualización",
    "title": "Situaciones de pobreza por ingreso en adultos mayores",
    "section": "Visualización",
    "text": "Visualización\nUna primera pregunta que sobrevuela desde el inicio de este trabajo es si efectivamente el haber mínimo logra cubrir el costo de la canasta básica de los jubilados. Lo averiguaremos imprimiendo un gráfico de ggplot2 de las dos curvas en paralelo:\n\n\nVer código\ndatosjub%>%\n  select(fecha,canasta,haber_minimo)%>%\n  gather('variable', 'monto', c(2:3))%>%\n  ggplot(.) +\n  aes(x = fecha, y = monto, colour = variable) +\n  geom_line(size = 0.9) +\n  scale_color_manual(values = c(canasta = \"#F8C36D\", \n                                haber_minimo = \"#7DA4E2\")) +\n    scale_x_date(date_labels = \"%Y/%m\",breaks = unique(datosjub$fecha))+\n  labs(title = \"Evolución comparada de la canasta básica de los jubilados\ny del haber mínimo previsional entre 2010 y 2022.\", \n       subtitle = \"Por año y mes de medición de la canasta.\", \n       x = \"Fecha\", y = \"Monto en pesos\", \n       caption = \"Fuente: elaboración propia en base a datos de la Subsecretaría \nde Programación Macroeconómica y la Defensoria del Pueblo de la Tercera Edad.\", \ncolor = \"Variable\") +\n  theme_light() +\n  theme(axis.text.x = element_text(angle = 45, size = 8))+\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nObservaremos que desde que comenzó a medirse la canasta de los jubilados en 2010, ésta siempre se mantuvo en ascenso y los haberes mínimos previsionales jamás llegaron a cubrirla.\nCon respecto a la cantidad de jubilaciones mínimas necesarias para alcanzar el costo de la canasta se verá lo siguiente:\n\n\nVer código\nlibrary(ggrepel)\n\nggplot(datosjub) +\n  aes(x = fecha, y = ncanasta) +\n  geom_line(size = 1.1, colour = \"gold\")+\n  geom_point(size = 3, colour = \"red\", alpha=0.2) +\n  scale_x_date(date_labels = \"%Y/%m\",breaks = unique(datosjub$fecha))+\n  geom_text_repel(aes(label = ncanasta), box.padding = 0.5, size=2.7)+\n  labs(title = \"Cantidad de haberes mínimos necesarios para cubrir\nla canasta básica del jubilado.\", \n       subtitle = \"Período 2010-2022\", \n       x = \"Fecha\", \n       y = \"Cantidad de haberes mínimos\", \ncaption = \"Fuente: elaboración propia en base a datos de la Subsecretaría \nde Programación Macroeconómica y la Defensoria del Pueblo de la Tercera Edad.\")+\n  theme_light()+\n  theme(axis.text.x = element_text(angle = 45, size = 8))\n\n\n\n\n\nSegún lo indica la gráfica, para el período de análisis, se han requerido no menos de dos haberes mínimos para empatar los valores de la canasta básica.\nSe generará para finalizar un último dato, relativo a la brecha porcentual entre canasta y haber mínimo.\n\n\nVer código\nlibrary(glue)\n\nbrecha<-datosjub%>%\n  mutate(brecha=round(c(canasta-haber_minimo)/canasta*1e2, \n                      digits = 1))\n\nbrecha%>%\n  ggplot() +\n  aes(x = fecha, y = brecha) +\n  geom_line(size = 1.1, colour = \"orange\") +\n  geom_point(size = 3, colour = \"red\", alpha=0.2) +\n  scale_x_date(date_labels = \"%Y/%m\",breaks = unique(datosjub$fecha))+\n  geom_text_repel(aes(label = glue(\"{brecha} %\")), box.padding = 0.5, size=2.7)+\n  labs(title = \"Brecha entre jubilación mínima y canasta del jubilado\", \n       subtitle = \"Periodo 2010-2022\", \n       x = \"Fecha\", \n       y = \"Brecha %\", \n       caption = \"Fuente: elaboración propia en base a datos de la Subsecretaría \nde Programación Macroeconómica y la Defensoria del Pueblo de la Tercera Edad.\")+ \n  theme_light()+\n  theme(axis.text.x = element_text(angle = 45, size = 8))\n\n\n\n\n\nDesde 2018 la brecha entre jubilaciones mínimas y canasta se mantiene en valores superiores al 60%.\nCuadro de síntesis:\n\n\nVer código\nlibrary(DT)\ndatosjub%>%\n  mutate(brecha=round(c(canasta-haber_minimo)/canasta*1e2, \n                      digits = 1))%>%\n  #select(fecha,canasta,haber_minimo,brecha)%>%\n  mutate_if(is.numeric, round, digits=1)%>%\n  datatable(extensions = 'Scroller', options = list(\n    deferRender = TRUE,\n    scrollY = 200,\n    scroller = TRUE\n  ))"
  },
  {
    "objectID": "posts/abuelos/index.html#reflexiones",
    "href": "posts/abuelos/index.html#reflexiones",
    "title": "Situaciones de pobreza por ingreso en adultos mayores",
    "section": "Reflexiones",
    "text": "Reflexiones\nA lo largo de este documento se ha recurrido a la potencia técnica de R y Quarto para dar cuenta, en forma exploratoria, de una situación de empobrecimiento progresivo de no menos de la mitad de hombres y mujeres que cobran el haber mínimo jubilatorio en Argentina.\nSi bien es importante destacar que en términos rigurosamente científicos -ya sean econométricos, como sociológicos o estadísticos- es necesario evaluar las mediciones de la canasta utilizada4, una canasta básica de $151.478 en un contexto en el que 6.000.000 de jubilados cobran una mínima de $43.000 y en el que el resto recibe un haber promedio de $ 65.000. Mientras que la Pensión Universal para Adultos Mayores (PUAM) es de $ 34.642 invita a repensar el rol y la prioridad que asignamos como sociedad a nuestros mayores. Rol y prioridad que, en parte, puede ser reconstruido analíticamente en base a las políticas de ingreso precario tomadas para el sector por el Estado Nacional en los últimos 10 años.\nEn un contexto económicamente acuciante como el que vive la Argentina, huelga no dejar de pensar los problemas de las grandes mayorías sociales, y dar nuevos debates acerca de la eficacia y eficiencia del sistema previsional actual, que en su devenir sume en una situación de pobreza creciente a lxs adultxs mayores, con todos los peligros latentes5 que ello implica para un colectivo que, según cita la bibliografía especializada, ya se encuentra vulnerado6 previamente de maneras múltiples.\n\nBonus:\n\n\nCómo vimos antes podemos correr código de r y python de manera complementaria. Es importante hacer estas triangulaciones para optimizar el análisis.\nPor ejemplo, corramos un chunk de python, para que se ejecute tenemos que tenerlo instalado en nuestra PC. Vamos levantar datos de salario mínimo y a compararlos con los de las de los haberes mínimos.\n\n\n\nVer código\n\nimport pandas as pd\n# consturimos nuestro dataframe\n\nurl=\"https://infra.datos.gob.ar/catalog/sspm/dataset/57/distribution/57.1/download/indice-salario-minimo-vital-movil-valores-mensuales-pesos-corrientes-desde-1988.csv\"\n\nc=pd.read_csv(url)\n\n#nos quedamos con dos variables\nsalarios = c[[\"indice_tiempo\", \"salario_minimo_vital_movil_mensual\"]]\n\n#chequeamos nuestros datos\nprint(salarios.head(5))\n\n#guardamos nuestro set en un csv\n\n\n  indice_tiempo  salario_minimo_vital_movil_mensual\n0    1965-01-01                              9800.0\n1    1965-02-01                              9800.0\n2    1965-03-01                              9800.0\n3    1965-04-01                              9800.0\n4    1965-05-01                             11550.0\n\n\nVer código\nsalarios.to_csv('salarios.csv')\n\n\n\nPodemos combinar los datos que descargamos en python con R para crear otras visualizaciones."
  },
  {
    "objectID": "posts/bienvenida/index.html",
    "href": "posts/bienvenida/index.html",
    "title": "El nuevo jornal sociológico de datos",
    "section": "",
    "text": "Motivación\nLa propuesta de crear este nuevo jornal sociológico de datos se basa en tres ideas-fuerza de orden general:\n\nActualizar y unificar mis distintos blogs en uno solo hecho 100% en Quarto, que es una tecnología contemporánea y permite generar narrativas basadas en datos combinando varios lenguajes de programación a la vez.\nExplorar en sí las posibilidades que brinda Quarto a la hora de comunicar los resultados de procesos de investigación basados en evidencia.\nÚltimo y fundamental, contar con una plataforma de trabajo para publicar ágilmente documentos de coyuntura, tutoriales, etc.\n\n\n\nOrganización de las publicaciones\nPara optimizar el acceso a los contenidos del blog, los mismos se organizan por categoría y cuentan con un filtro dinámico para buscar temas específicos o palabras clave.\nLa propuesta será de aquí en más publicar sobre distintos temas con una cierta periodicidad buscando sistematizar experiencias de investigación y formación basadas en R .\nVamos por eso!\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{damiánorden2022,\n  author = {Pedro Damián Orden},\n  editor = {},\n  title = {El Nuevo Jornal Sociológico de Datos},\n  date = {2022-09-01},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPedro Damián Orden. 2022. “El Nuevo Jornal Sociológico de\nDatos.” September 1, 2022."
  },
  {
    "objectID": "posts/elecciones/index.html",
    "href": "posts/elecciones/index.html",
    "title": "Apuntes sobre preferencia electoral en la Ciudad de Lanús en las legislativas de 2021",
    "section": "",
    "text": "En este documento electrónico exploraremos el desempeño de las agrupaciones políticas ponderado por circuito electoral en la Elección General de 2021 para la categoría concejal en el Municipio de Lanús (Provincia de Buenos Aires)."
  },
  {
    "objectID": "posts/elecciones/index.html#obtención-de-datos",
    "href": "posts/elecciones/index.html#obtención-de-datos",
    "title": "Apuntes sobre preferencia electoral en la Ciudad de Lanús en las legislativas de 2021",
    "section": "Obtención de datos",
    "text": "Obtención de datos\nPara desandar la exploración se utilizarán los datos detallados de las Elecciones Generales de 2021, obtenidos previamente por medio de un pedido de información pública a la Cámara Nacional Electoral. El dataset contiene los resultados que obtuvieron las agrupaciones para la categoría concejal por escuela, circuito y distrito en Lanús.\n\n\nVer código\nlibrary(readr)\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(leaflet)\nlibrary(ggthemes)\nlibrary(viridis)\nlibrary(fst)\n\nmesas_escrutadas<-read.csv(\"https://raw.githubusercontent.com/pedroorden/concejales2021/main/mesas_escrutadas.csv\", encoding=\"UTF-8\")\n\n\nApliquemos algunas funciones de resumen para conocer nuestros datos:\nhead\n\n\nVer código\nhead(mesas_escrutadas)\n\n\n  X Agrupacion      Cargo Codigo     Distrito\n1 1       <NA> CONCEJALES   6370 Buenos Aires\n2 2       <NA> CONCEJALES   6370 Buenos Aires\n3 3       <NA> CONCEJALES   6370 Buenos Aires\n4 4       <NA> CONCEJALES   6370 Buenos Aires\n5 5       <NA> CONCEJALES   6370 Buenos Aires\n6 6     JUNTOS CONCEJALES   6370 Buenos Aires\n                        Establecimiento            Fecha IdCargo IdCircuito\n1 ESCUELA EP N<U+00B0>19/ES N<U+00B0>48 14-11-2021 18:55       7        276\n2 ESCUELA EP N<U+00B0>19/ES N<U+00B0>48 14-11-2021 18:55       7        276\n3 ESCUELA EP N<U+00B0>19/ES N<U+00B0>48 14-11-2021 18:55       7        276\n4 ESCUELA EP N<U+00B0>19/ES N<U+00B0>48 14-11-2021 18:55       7        276\n5 ESCUELA EP N<U+00B0>19/ES N<U+00B0>48 14-11-2021 18:55       7        276\n6 ESCUELA EP N<U+00B0>19/ES N<U+00B0>48 14-11-2021 18:55       7        276\n  IdDistrito IdSeccion   Mesa  Seccion electores envio idAgrupacion\n1          2        62 01015X Lan<fa>s       355     6           NA\n2          2        62 01015X Lan<fa>s       355     6           NA\n3          2        62 01015X Lan<fa>s       355     6           NA\n4          2        62 01015X Lan<fa>s       355     6           NA\n5          2        62 01015X Lan<fa>s       355     6           NA\n6          2        62 01015X Lan<fa>s       355     6          506\n  idAgrupacionInt   tipoVoto votos\n1              NA    blancos     6\n2              NA      nulos     0\n3              NA recurridos     0\n4              NA    comando     0\n5              NA impugnados     0\n6              43   positivo   133\n\n\nsummary\n\n\nVer código\nsummary(mesas_escrutadas)\n\n\n       X          Agrupacion           Cargo               Codigo     \n Min.   :    1   Length:11230       Length:11230       Min.   : 6216  \n 1st Qu.: 2808   Class :character   Class :character   1st Qu.: 6272  \n Median : 5616   Mode  :character   Mode  :character   Median : 6331  \n Mean   : 5616                                         Mean   :11242  \n 3rd Qu.: 8423                                         3rd Qu.:11589  \n Max.   :11230                                         Max.   :40223  \n                                                                      \n   Distrito         Establecimiento       Fecha              IdCargo \n Length:11230       Length:11230       Length:11230       Min.   :7  \n Class :character   Class :character   Class :character   1st Qu.:7  \n Mode  :character   Mode  :character   Mode  :character   Median :7  \n                                                          Mean   :7  \n                                                          3rd Qu.:7  \n                                                          Max.   :7  \n                                                                     \n   IdCircuito      IdDistrito   IdSeccion      Mesa          \n Min.   :259.0   Min.   :2    Min.   :62   Length:11230      \n 1st Qu.:262.0   1st Qu.:2    1st Qu.:62   Class :character  \n Median :265.0   Median :2    Median :62   Mode  :character  \n Mean   :267.8   Mean   :2    Mean   :62                     \n 3rd Qu.:274.0   3rd Qu.:2    3rd Qu.:62                     \n Max.   :276.0   Max.   :2    Max.   :62                     \n                                                             \n   Seccion            electores         envio        idAgrupacion  \n Length:11230       Min.   : 98.0   Min.   : 6.00   Min.   :503.0  \n Class :character   1st Qu.:350.0   1st Qu.:19.00   1st Qu.:504.0  \n Mode  :character   Median :351.0   Median :24.00   Median :506.0  \n                    Mean   :356.2   Mean   :27.49   Mean   :505.6  \n                    3rd Qu.:353.0   3rd Qu.:36.00   3rd Qu.:507.0  \n                    Max.   :576.0   Max.   :68.00   Max.   :508.0  \n                                                    NA's   :5615   \n idAgrupacionInt   tipoVoto             votos       \n Min.   :40.0    Length:11230       Min.   :  0.00  \n 1st Qu.:41.0    Class :character   1st Qu.:  0.00  \n Median :43.0    Mode  :character   Median :  8.00  \n Mean   :42.6                       Mean   : 24.73  \n 3rd Qu.:44.0                       3rd Qu.: 21.00  \n Max.   :45.0                       Max.   :164.00  \n NA's   :5615                                       \n\n\nclass\n\n\nVer código\nclass(mesas_escrutadas)\n\n\n[1] \"data.frame\"\n\n\nnames\n\n\nVer código\nnames(mesas_escrutadas)\n\n\n [1] \"X\"               \"Agrupacion\"      \"Cargo\"           \"Codigo\"         \n [5] \"Distrito\"        \"Establecimiento\" \"Fecha\"           \"IdCargo\"        \n [9] \"IdCircuito\"      \"IdDistrito\"      \"IdSeccion\"       \"Mesa\"           \n[13] \"Seccion\"         \"electores\"       \"envio\"           \"idAgrupacion\"   \n[17] \"idAgrupacionInt\" \"tipoVoto\"        \"votos\"          \n\n\ndim\n\n\nVer código\ndim(mesas_escrutadas)\n\n\n[1] 11230    19\n\n\nLos primeros resultados indican que se trata de un conjunto de datos con 11.230 observaciones y 19 variables, en formato numérico y de texto."
  },
  {
    "objectID": "posts/elecciones/index.html#transformación",
    "href": "posts/elecciones/index.html#transformación",
    "title": "Apuntes sobre preferencia electoral en la Ciudad de Lanús en las legislativas de 2021",
    "section": "Transformación",
    "text": "Transformación\nCreamos un nuevo conjunto de datos que filtra sólo los votos positivos que obtuvieron las agrupaciones, tal como lo establece la Constitución Nacional para realizar los conteos en las elecciones generales.\nLlegado este punto se procesa, por circuito electoral, la cantidad de votos de cada una de las agrupaciones por la cantidad de electores, con el objetivo de generar una nueva variable de ponderación llamada ratio_electoral.\n\n\nVer código\nlanus1<-mesas_escrutadas%>%\n  filter(tipoVoto==\"positivo\")%>% #filtra votos positivos\n  group_by(IdCircuito, Agrupacion)%>%\n  summarise(votosxcirc=sum(votos),\n            electoresxcirc=sum(electores))%>%\n  mutate(ratio_electoral=votosxcirc/electoresxcirc)%>% #crea ratio_electoral\n  mutate(IdCircuito=as.factor(IdCircuito))\n\n\nEl agregado de ratio_electoral es una decisión teórica que procura dar cuenta de la especificidad local de cada circuito electoral de Lanús, y coadyuvar a una exploración comparativa de los datos en dos sentidos:\n\nLa lectura del fenómeno del voto para una agrupación particular, por circuito electoral, para detectar zonas con mejor o peor ratio_electoral voto/electores.\nLa comparación general del ratio_electoral por circuito electoral de las distintas agrupaciones."
  },
  {
    "objectID": "posts/elecciones/index.html#primeras-impresiones",
    "href": "posts/elecciones/index.html#primeras-impresiones",
    "title": "Apuntes sobre preferencia electoral en la Ciudad de Lanús en las legislativas de 2021",
    "section": "Primeras impresiones",
    "text": "Primeras impresiones\nEl nuevo df lanus1 consta de 5 variables, 65 observaciones. Suma los votos afirmativos totales por circuito electoral de las distintas agrupaciones, además de calcular la performance de las mismas ponderando la razón votos/electores.\nCon este set ya estaremos en condiciones de comenzar a reflexionar en torno a la preferencia electoral en 2021 de los y las lanusenses a escala de circuito electoral."
  },
  {
    "objectID": "posts/elecciones/index.html#exploración-gráfica",
    "href": "posts/elecciones/index.html#exploración-gráfica",
    "title": "Apuntes sobre preferencia electoral en la Ciudad de Lanús en las legislativas de 2021",
    "section": "Exploración Gráfica",
    "text": "Exploración Gráfica\nAntes de generar nuestros mapas será importante visualizar la cantidad de electores por circuito para conocer el peso cuantitativo de cada uno.\n\n\nVer código\nlanus1%>%\n  select(IdCircuito, electoresxcirc)%>%\n  unique()%>%\n  arrange(electoresxcirc)%>%\n  ggplot() +\n  aes(x=reorder(IdCircuito,-electoresxcirc), \n      y = electoresxcirc) +\n  geom_point(aes(size = electoresxcirc, \n                 fill = electoresxcirc),\n             shape = 21, alpha = 0.7) +\n  scale_fill_viridis_c(guide = \"legend\") +\n  labs(x = \"Circuito número\",\n       y = \"Total electores\",\n       title = \"Cuadro 1: Total de electores por circuito electoral\",\n       subtitle = \"\",\n       caption = \"Fuente: elaboración propia en base a datos de la CNE.\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nEl circuito con mayor cantidad de electores es el 262 y el que menos tiene el 264.\nSeguidamente nos interesará conocer cómo se plasma la variable ratio_electoral de cada fuerza por circuito electoral, para ello se presenta un cuadro con gráficas barra facetadas.\n\n\nVer código\nggplot(lanus1) +\n  aes(x = IdCircuito, y = ratio_electoral, fill = IdCircuito) +\n  geom_col() +\n  labs(\n    x = \"Circuito número\",\n    y = \"ratio votos/electores\",\n    title = \"Cuadro 2: Razon votantes/electores por circuito\",\n    subtitle = \"\",\n    caption = \"Fuente: elaboración propia en base a datos de la CNE.\") +\n  coord_flip() +\n  theme_linedraw() +\n  theme(legend.position = \"none\",\n        strip.text.x = element_text(size = 4.1))+\n  facet_wrap(vars(Agrupacion))\n\n\n\n\n\n\n\n\n\nCon esta primera imagen podremos observar que las agrupaciones Juntos y Frente de Todos presentaron las valores más altos para la variable ratio_electoral, destacando el Frente de Izquierda como la que tuvo mejor performance entre aquellas fuerzas con menor caudal de votos."
  },
  {
    "objectID": "posts/elecciones/index.html#mapeo-de-electores-por-circuito",
    "href": "posts/elecciones/index.html#mapeo-de-electores-por-circuito",
    "title": "Apuntes sobre preferencia electoral en la Ciudad de Lanús en las legislativas de 2021",
    "section": "Mapeo de electores por circuito",
    "text": "Mapeo de electores por circuito\nPara localizar los datos previamente explorados procederemos a obtener un archivo con las coordenadas geográficas de los circuitos electorales de Lanús.\n\n\nVer código\ncircuitos <- read_sf(\"https://github.com/pedroorden/concejales2021/raw/main/circuitos02_cne.geojson\")%>%\n  filter(departamen==\"Lanús\")%>%\n  mutate(IdCircuito=substring(circuito, 2))\n\n\nLos mismos se unen al objeto lanus1 para crear lanus2 como conjunto de datos geográficos.\n\n\nVer código\nlanus2<-lanus1%>%\n  left_join(circuitos, by=\"IdCircuito\")%>%\n  st_as_sf()\n\n\nSe genera un mapa leaflet recreando espacialmente el ejercicio propuesto en el cuadro 1. La escala viridis será utilizada aquí, y a lo largo de todo el trabajo, para reflejar visualmente la mayor (color claro) o menor (color oscuro) magnitud de un fenómeno, por ej: electores, votos, ratio_electoral, etc.\n\n\n\n\n\n\nLa localización de los datos en un mapa permite reconocer los circuitos más poblados, son el 273 y 262, al norte y sur del municipio respectivamente. 264 y 259 son aquellos circuitos que cuentan con menos electores."
  },
  {
    "objectID": "posts/elecciones/index.html#ratio_electoral-por-agrupación",
    "href": "posts/elecciones/index.html#ratio_electoral-por-agrupación",
    "title": "Apuntes sobre preferencia electoral en la Ciudad de Lanús en las legislativas de 2021",
    "section": "ratio_electoral por agrupación",
    "text": "ratio_electoral por agrupación\nPosteriormente, se recrea con ggplot la propuesta del cuadro 2 para visualizar en un mapa de cloropetas la variable ratio_electoral (votos/electores) por circuito electoral para las distintas agrupaciones.\n\n\n\n\nJuntos\n\n\n\n\n\n\n\n\n\n\n\nFPV\n\n\n\n\n\n\n\n\n\n\n\nAvanza Libertad\n\n\n\n\n\n\n\n\n\n\n\nFrente de Izquierda\n\n\n\n\n\n\n\n\n\n\n\nVamos con vos"
  },
  {
    "objectID": "posts/elecciones/index.html#comparativas",
    "href": "posts/elecciones/index.html#comparativas",
    "title": "Apuntes sobre preferencia electoral en la Ciudad de Lanús en las legislativas de 2021",
    "section": "Comparativas",
    "text": "Comparativas\nLa próxima secuencia realiza un facetado que compara mediante dos gráficos con escalas diferenciadas las dos agrupaciones con mayor ratio_electoral por un lado y las terceras fuerzas con sus respectivos valores por otro.\n\n\nVer código\na1<-lanus2%>%\n  # filter(!Agrupacion %in% c(\"JUNTOS\",\"FRENTE DE TODOS\"))%>%\n  filter(Agrupacion %in% c(\"FRENTE DE TODOS\", \"JUNTOS\"))%>%\n  ggplot() +  \nlabs(title = \"Razon votantes/electores por circuito\",\n         subtitle = \"Elecciones generales 2021 para la categoría concejal en Lanús.\",\n       caption = \"Fuente: elaboración propia en base a datos de la CNE.\") +  geom_sf(aes(fill = ratio_electoral)) + \n  facet_wrap(~Agrupacion)+\n  scale_fill_viridis_c() +\n  theme_map()+\n  theme(legend.position = \"bottom\") +\n  theme(axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank(),\n        strip.text.x = element_text(size = 6),\n        axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank())\n\nb2<-lanus2%>%\n  # filter(!Agrupacion %in% c(\"JUNTOS\",\"FRENTE DE TODOS\"))%>%\n  filter(Agrupacion %in% c(\"FRENTE DE IZQUIERDA Y DE TRABAJADORES - UNIDAD\", \"FRENTE VAMOS CON VOS\", \"AVANZA LIBERTAD\"))%>%\n  ggplot() +  \n  geom_sf(aes(fill = ratio_electoral)) + \n      labs(title = \"Razon votantes/electores por circuito\",\n         subtitle = \"Elecciones generales 2021 para la categoría concejal en Lanús.\",\n       caption = \"Fuente: elaboración propia en base a datos de la CNE.\") +\n  facet_wrap(~Agrupacion)+\n  scale_fill_viridis_c() +\n  theme_map()+\n  theme(legend.position = \"bottom\") +\n  theme(axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank(),\n        strip.text.x = element_text(size = 6),\n        axis.title.y=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks.y=element_blank())\n\n\n\nJuntos | Frente De todos\n\n\n\n\n\n\n\n\n\nEl mapa que compara FDT y Juntos denota un patrón en el cual los circuitos del centro tienden a manifestar una preferencia electoral por Juntos y los de la periferia por el Frente de Todos.\n\n\nFrente de Izquierda| Avanza Libertad| Vamos Con Vos\n\n\n\n\n\n\n\n\n\nCon respecto a las terceras fuerzas el panorama presenta mayor complejidad puesto que el Frente de Izquierda y Avanza Libertad presentan situaciones similares, aunque la Izquierda con una leve mejoría en la variable ratio_electoral circuito por circuito. Con respecto al Frente Vamos Con Vos en la comparativa sólo muestra mayor presencia en un territorio del norte del municipio."
  },
  {
    "objectID": "posts/elecciones/index.html#conclusiones",
    "href": "posts/elecciones/index.html#conclusiones",
    "title": "Apuntes sobre preferencia electoral en la Ciudad de Lanús en las legislativas de 2021",
    "section": "Conclusiones",
    "text": "Conclusiones\nEl presente documento electrónico procuró abordar un fenómeno concreto y medible: las Elecciones Generales en Lanús de 2021, específicamente los resultados para la categoría concejal , con datos agrupados por circuito electoral.\nCon la intensión de encontrar en los datos uno o mas insights, se construyó la variable ratio_electoral que ha permitido realizar una lectura ponderada de los votos por circuito electoral para reconocer visualmente cual fue el desempeño de cada agrupación en cuanto a los votos ajustados por la cantidad de electores totales por territorio.\nLos resultados de esta exploración gráfica de carácter general indican que la fuerza que mejor desempeño ha tenido en la compulsa por circuito electoral ha sido Juntos, aunque el Frente de Todos ese mantuvo cerca, ganando en los circuitos con mayor cantidad de electores.\nLas terceras fuerzas quedaron lejos de las dos primeras, lo cual daría cuenta de un aparente carácter bipartidista en la gimnasia política de Lanús. Aún así, el Frente de Izquierda es la agrupación que levemente emerge con una mejor performance por sobre Avanza Libertad y el Frente Vamos Con Vos.\nSi bien como reza el refrán popular “al final del día todos los votos valen 1”, la exploración de la relación voto/electores ponderada por circuito ha permitido conocer la penetración de una agrupación en un territorio dado y se presta como un insumo complementario para evaluar cuestiones tales como estrategias políticas, campañas de comunicación y la gestión de los siempre escasos rescursos de militancia.\nQuedará para futuros trabajos seguir explorando estos datos con nuevas aperturas, temporalidades y sumando nuevos algoritmos."
  },
  {
    "objectID": "posts/encuestas/index.html",
    "href": "posts/encuestas/index.html",
    "title": "Procesando datos de encuestas Con R",
    "section": "",
    "text": "El presente documento es un material de taller pensado para profesionales de las ciencias sociales y público interesado. Se procura aquí presentar de manera introductoria una serie de procedimientos asociados al procesamiento de encuestas con R.\nUna versión de este documento fue presentada en un Taller abierto del NIS el 16 de septiembre de 2022 y grabada en vivo para que todos y todas puedan replicar la experiencia código a código.\nLas diapositivas utilizadas en la primera parte del encuentro pueden encontrarse aquí."
  },
  {
    "objectID": "posts/encuestas/index.html#contenidos",
    "href": "posts/encuestas/index.html#contenidos",
    "title": "Procesando datos de encuestas Con R",
    "section": "Contenidos",
    "text": "Contenidos\nVeremos aquí:\n\nCarga de datos de un formulario drive y transformación.\nAnálisis preliminar/exploratorio.\nVisualización.\nRecomendaciones profesionales: skimr, esquisser y janitor."
  },
  {
    "objectID": "posts/encuestas/index.html#carga-de-datos",
    "href": "posts/encuestas/index.html#carga-de-datos",
    "title": "Procesando datos de encuestas Con R",
    "section": "Carga de datos",
    "text": "Carga de datos\nLos datos de trabajo pertenecen a una sub-muestra de una encuesta realizada por los Colegios Profesionales de Buenos Aires y el NIS a comienzos de la pandemia, los mismos son 100% anónimos y fueron recabados por medio de un formulario Google.\nComenzamos cargando en R las respuestas de drive (previamente debemos compartirlo como público en la web, en formato csv) y creamos el objeto muestra1.\n\n\nVer código\nmuestra1<-read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vTbdWYdjYhfvt8quj9A5LpIEhH-sSKwxTsG8lKLLK_E_C5r1tkqFNdQNSAdzXvgthWCrFDn7oiN3-9P/pub?gid=346447959&single=true&output=csv\",encoding = \"UTF-8\")\n\n\nExploramos con funciones base de R nuestros datos (todavía no estamos usando paquetes).\nIndagamos acerca de la clase de nuestros datos:\n\n\nVer código\nclass(muestra1)\n\n\n[1] \"data.frame\"\n\n\nConsultamos la dimensión del conjunto de datos, filas y columnas:\n\n\nVer código\ndim(muestra1)\n\n\n[1] 627  24\n\n\nY podríamos seguir así…pero no, cargamos el (muy genial) paquete skimr el cual nos ayudará a crear un primer resumen de las características de nuestro set de datos (tengamos presente que para correr un paquete primero hay que instalarlo).\n\n\nVer código\n#install.packages(\"skimr\") #lo grisado no se ejecuta\nlibrary(skimr)\nskim(muestra1)\n\n\n\nData summary\n\n\nName\nmuestra1\n\n\nNumber of rows\n627\n\n\nNumber of columns\n24\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n19\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nMarca.temporal\n0\n1\n17\n19\n0\n622\n0\n\n\nX.Estás.haciendo.cuarentena.\n0\n1\n2\n2\n0\n2\n0\n\n\nTe.identificas.como.\n0\n1\n0\n6\n9\n3\n0\n\n\nX.En.qué.provincia.vivís.actualmente.\n0\n1\n0\n31\n9\n18\n0\n\n\nX.Cuál.es.el.máximo.nivel.educativo.que.completaste.\n0\n1\n0\n36\n9\n9\n0\n\n\nX.Cuál.es.tu.principal.ocupación.\n0\n1\n0\n156\n9\n11\n0\n\n\nX.Estas.trabajando.desde.tu.casa.bajo.alguna.modalidad.de.tele.trabajo..home.office..\n0\n1\n0\n29\n119\n4\n0\n\n\nX.Tenes.hijos.en.edad.escolar.\n0\n1\n0\n49\n9\n5\n0\n\n\nX.Estás.viviendo.con.ellos.durante.esta.cuarentena.\n0\n1\n0\n68\n310\n4\n0\n\n\nDe.la.siguiente.lista..Cuáles.son.tus.tres.principales.medios.para.informarte.sobre.los.asuntos.del.país.y.la.circunstancia.del.coronavirus.\n0\n1\n0\n151\n9\n246\n0\n\n\nX.Te.gustaría.nombrar.algún.otro.medio.que.estés.usando.\n0\n1\n0\n125\n224\n119\n0\n\n\nX.Cambiaste.la.forma.en.que.te.informas.desde.que.comenzó.la.cuarentena.\n0\n1\n0\n2\n9\n3\n0\n\n\nX.Cómo.cambió.la.forma.en.que.te.informaste\n0\n1\n0\n626\n426\n201\n0\n\n\nX.Recibiste.noticias..información.relacionada.al.coronavirus.y.o.la.cuarentena.que.resultaron.ser.falsas.\n0\n1\n0\n5\n9\n4\n0\n\n\nX.Recordas.a.través.de.qué.medio.recibiste.esa.información.falsa.\n0\n1\n0\n152\n159\n103\n0\n\n\nX.Crees.que.las.noticias.falsas.o.fake.news.están.influyendo.en.el.comportamiento.de.las.personas.\n0\n1\n0\n5\n9\n4\n0\n\n\nX.Cómo.crees.que.influyen.las.noticias.falsas.o.fake.news.están.influyendo.en.el.comportamiento.de.las.personas.\n0\n1\n0\n909\n212\n400\n0\n\n\nX.Cuál.es.la.ocupación.de.la.persona.que.realiza.el.principal.aporte.económico.\n0\n1\n0\n167\n9\n11\n0\n\n\nAnte.una.emergencia.médica..problema.de.salud..a.dónde.acudis.primero.\n0\n1\n0\n116\n12\n20\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nX.Cuántos.años.tenés.\n9\n0.99\n42.48\n13.65\n18\n32\n40\n53\n82\n▅▇▅▃▁\n\n\nX.En.qué.medida.te.sentís.informado.a.acerca.de.las.medidas.de.prevención.del.Coronavirus.\n9\n0.99\n4.28\n0.79\n1\n4\n4\n5\n5\n▁▁▂▆▇\n\n\nX.Cuál.es.tu.opinión.acerca.de.lo.que.comunican.los.medios.de.comunicación.argentinos.sobre.el.Coronavirus.\n9\n0.99\n3.34\n0.89\n1\n3\n3\n4\n5\n▁▂▇▆▂\n\n\nX.Cuántas.personas.viven.en.tu.hogar.incluyéndote.a.vos.\n9\n0.99\n3.54\n20.97\n0\n2\n2\n4\n522\n▇▁▁▁▁\n\n\nX.y.cuántas.realizan.algún.tipo.de.aporte.económico.\n9\n0.99\n1.78\n0.81\n0\n1\n2\n2\n5\n▆▇▂▁▁\n\n\n\n\n\nUn resumen de nuestros datos con dos líneas de código, genial no? Este tipo de paquetes y funciones caracterizan a R, existen muchos desarrollos de la comunidad que pueden ayudarnos en nuestra labor diaria. Lo importante es conocerlos y contar con el criterio de saber en qué momento y cómo usarlos."
  },
  {
    "objectID": "posts/encuestas/index.html#limpieza-de-datos",
    "href": "posts/encuestas/index.html#limpieza-de-datos",
    "title": "Procesando datos de encuestas Con R",
    "section": "Limpieza de datos",
    "text": "Limpieza de datos\nComo hemos visto, tenemos una muestra de respondentes y la propuesta es ahora presentar algunos cálculos de estadística descriptiva y generar visualizaciones, ya que una parte importante de nuestro trabajo con encuestas tiene que ver con armar gráficos que reflejen el comportamiento de variables.\nAhora bien, antes de avanzar precisamos hacerle algunos ajustes a nuestros datos.\nPara llevar adelante este proceso vamos a cargar dos paquetes muy útiles para transformar datos -tidyverse- y normalizar fechas -lubridate-.\n\n\nVer código\n#install.packages(\"tidyverse\")\nlibrary(tidyverse)\n#install.packages(\"lubridate\")\nlibrary(lubridate)\n\n\nCreamos el objeto muestra2, son nuestros datos de partida con fechas normalizadas y espacios en blanco reemplazados por NAs (mejora el procesamiento). Lo hacemos mediante las siguientes transformaciones:\n\n\nVer código\nmuestra2<-muestra1%>% #pipe de tidyverse\n  mutate(Marca.temporal=sub(\" .*\", \"\", Marca.temporal))%>%\n  #transformamos nuestros datos\n  mutate(Marca.temporal=dmy(Marca.temporal))%>% #formateamos fecha\n  mutate_if(is.character, list(~na_if(.,\"\")))"
  },
  {
    "objectID": "posts/encuestas/index.html#primeras-preguntas",
    "href": "posts/encuestas/index.html#primeras-preguntas",
    "title": "Procesando datos de encuestas Con R",
    "section": "Primeras preguntas",
    "text": "Primeras preguntas\nDado el ajuste rápido de nuestros datos, queremos conocer más sobre el proceso de campo del formulario, por ejemplo: entre qué fechas tuvo lugar y cuántos respondentes tuvo por día?\nVeamos qué podemos decir con nuestro objeto muestra2:\n\n\nVer código\nrespuestas <- muestra2%>%\n  group_by(Marca.temporal)%>% #agrupamos por fecha\n  count() #contamos respuestas por fecha\n\nrespuestas\n\n\n# A tibble: 25 x 2\n# Groups:   Marca.temporal [25]\n   Marca.temporal     n\n   <date>         <int>\n 1 2020-03-31         2\n 2 2020-04-06       367\n 3 2020-04-07       116\n 4 2020-04-08        50\n 5 2020-04-09        23\n 6 2020-04-10        27\n 7 2020-04-11         5\n 8 2020-04-12         2\n 9 2020-04-13         4\n10 2020-04-14         3\n# ... with 15 more rows\n\n\nGraficamos las respuestas por día con ggplot2, una librería R que sirve para hacer gráficos. Viene con el paquete tidyverse que ya tenemos activado.\nVeamos como opera la lógica de estos gráficos en la práctica:\n\n\nVer código\nrespuestas%>% #nuestro objeto\n  ggplot() + #declara la funcion para graficar el objeto\n  aes(x = Marca.temporal, y = n) + #idicamos las variables a graficar\n  geom_line(size = 0.5) #una geometria que la exprese, en este caso es una linea\n\n\n\n\n\nVemos que el momento de nuestro campo tuvo un período de actividad desde finales de marzo y durante todo abril, luego registró respuestas esporádicas (por error).\nRepitamos el ejercicio poniendo nuestra atención en el lapso temporal en el que se registró la mayor cantidad de respuestas basándonos en la referencia visual que creamos.\n\n\nVer código\nrespuestas%>%\n  filter(!Marca.temporal>=\"2020-05-01\")%>% #excluimos mayo 2020 en adelante\n  ggplot() + #declara la funcion para graficar el objeto\n  aes(x = Marca.temporal, y = n) + #una geometria que la exprese, en este caso es una linea\n  geom_line(size = 0.9) #aumentamos la linea\n\n\n\n\n\nPresentamos ahora una tecnología facilitadora del proceso que acabamos de realizar."
  },
  {
    "objectID": "posts/encuestas/index.html#gráficos-con-la-librería-esquisse",
    "href": "posts/encuestas/index.html#gráficos-con-la-librería-esquisse",
    "title": "Procesando datos de encuestas Con R",
    "section": "Gráficos con la librería Esquisse",
    "text": "Gráficos con la librería Esquisse\nAntes de contarles qué hace, veamos cómo funciona:\n\n\nVer código\n#install.packages(\"esquisse\")\nlibrary(esquisse)\n# grisamos nuestro codigo como un machete.\n# lo a ctivamos para consulta \n# respuestas%>%\n#   esquisser()\n\n\n\nImportante: se recomienda ver el video del inicio para acompañar la explicación acerca de como funciona esquisse.\n\nEsquisse ayuda a explorar y visualizar nuestros datos de forma interactiva. El paquete crea gráficos ggplot de manera ágil por medio de una interfaz basada en arrastrar, soltar y filtrar para luego exportar los resultados como .png, .jpg o recuperar el código.\nPlantea dos utilidades principales:\n\nEDA al instante: aunque ggplot es muy rápido y fácil de usar, esquisse permite explorar visualmente los datos en todos los ángulos con una variedad de tipos de gráficos, filtros, agrupaciones, etc.\nConocer ggplot : con este paquete se puede crear rápidamente un gráfico, mirar el código, hacer un cambio, ver cómo eso impactó en el código y repetir.\n\nComo se distribuye la variable edad de nuestra muestra? lo exploramos con esquisse.\n\n\nVer código\n# muestra2%>%\n#   esquisser()\n\n# Cod: ejemplo\n  ggplot(muestra2) +\n  aes(x = X.Cuántos.años.tenés.) +\n  geom_histogram(bins = 10L, fill = \"#46337E\") +\n  labs(\n    x = \"años\",\n    y = \"n respondentes\",\n    title = \"Distribucion de la variable edad\",\n    subtitle = \"datos de muestra\"\n  ) +\n  theme_light()"
  },
  {
    "objectID": "posts/encuestas/index.html#calculemos-porcentuales",
    "href": "posts/encuestas/index.html#calculemos-porcentuales",
    "title": "Procesando datos de encuestas Con R",
    "section": "Calculemos porcentuales",
    "text": "Calculemos porcentuales\nEl paquete janitor es otro aliado imprescindible ya que suma una una gama extra de funcionalidades a la hora de limpiar datos, entre las más destacables: genera nombres de columnas legibles, elimina columnas y filas vacías y encuentra valores duplicados. Aquí la usaremos para un proceso muy específico que es la creación de tablas de frecuencias y porcentuales.\n\n\nVer código\n#install.packages(\"janitor\")\nlibrary(janitor)\n\ncuarentena<-muestra2%>%\n    tabyl(X.Estás.haciendo.cuarentena.)\n\nprint(cuarentena)\n\n\n X.Estás.haciendo.cuarentena.   n    percent\n                           No   9 0.01435407\n                           Sí 618 0.98564593\n\n\nEl recorte de nuestra muestra indica que casi el 99% estaba haciendo cuarentena al momento de responder el formulario.\nCrucemos ahora estos datos con la variable de tenencia de hijos en edad escolar, para crear una tabla de doble entrada.\n\n\nVer código\ncruce <- muestra2 %>%\n  rename(hace_home=X.Estas.trabajando.desde.tu.casa.bajo.alguna.modalidad.de.tele.trabajo..home.office..)%>%\n  tabyl(X.Tenes.hijos.en.edad.escolar., \n        hace_home,\n        show_na = FALSE)%>%\n  adorn_percentages(\"row\")\n\ncruce\n\n\n                    X.Tenes.hijos.en.edad.escolar.        No        Sí\n                                No, no tengo hijos 0.2154472 0.7276423\n                   Sí, tengo hijos en edad escolar 0.2352941 0.6993464\n Sí, tengo hijos pero aún no están en edad escolar 0.3000000 0.7000000\n    Sí, tengo hijos pero ya no tienen edad escolar 0.2323232 0.7373737\n Siempre trabajo desde mi casa\n                    0.05691057\n                    0.06535948\n                    0.00000000\n                    0.03030303\n\n\nVer código\n# y si lo esquisiamos (?\n# cruce%>%\n#   esquisser() #que pasa?\n\n\nAsi como los estamos exportando no podemos graficarlos con ggplot ya que se multiplican las columnas con información. Para evitar que esto pase, un procedimiento habitual es volver a transformar nuestros datos en un par clave-valor.\n\n\nVer código\ncruce2 <- cruce%>%\n  gather('hace_home', 'pct', c(2:4))%>% #reune varias columnas para convertirlas en un par clave-valor\n  mutate(pct=round(pct*100, 1))# formateamos porcentaje\n\nhead(cruce2)\n\n\n                     X.Tenes.hijos.en.edad.escolar. hace_home  pct\n1                                No, no tengo hijos        No 21.5\n2                   Sí, tengo hijos en edad escolar        No 23.5\n3 Sí, tengo hijos pero aún no están en edad escolar        No 30.0\n4    Sí, tengo hijos pero ya no tienen edad escolar        No 23.2\n5                                No, no tengo hijos        Sí 72.8\n6                   Sí, tengo hijos en edad escolar        Sí 69.9\n\n\nVer código\n#checkeamos\n# cruce2%>%\n#   esquisser()\n\n\nCon nuestro datos transformados podríamos generar un gráfico de base similar a este:\n\n\nVer código\nggplot(cruce2) +\n aes(x = X.Tenes.hijos.en.edad.escolar., y = pct, fill = hace_home) +\n geom_col() +\n scale_fill_hue(direction = 1) +\n  theme(axis.text.x = element_text(angle = 45))"
  },
  {
    "objectID": "posts/encuestas/index.html#procesando-variable-de-escala-likert",
    "href": "posts/encuestas/index.html#procesando-variable-de-escala-likert",
    "title": "Procesando datos de encuestas Con R",
    "section": "Procesando variable de escala Likert",
    "text": "Procesando variable de escala Likert\nO casi. Transformamos la pregunta: en qué medida te sentís informado a acerca de las medidas de prevención del Coronavirus, con una escala de 1 a 5, donde 1 es nada informado/a y 5 es muy informado/a.\n\n\nVer código\nmuestra3<-muestra1%>%\n  rename(informa=X.En.qué.medida.te.sentís.informado.a.acerca.de.las.medidas.de.prevención.del.Coronavirus.)%>%\n  tabyl(informa, \n        show_na = FALSE)\n\nmuestra3<-muestra3%>%\n  mutate(percent=round(percent*100,1))%>%\n  mutate(informa=case_when(informa==1~\"1 nada informado/a\",\n                           informa==2~\"2 un poco informado/a\",\n                           informa==3~\"3 informado/a\",\n                           informa==4~\"4 bastante informado/a\",\n                           informa==5~\"5 muy informado/a\"))%>%\n  mutate(informa=as.factor(informa))\n\n#repetimos el esquisseo (??\n# muestra3%>%\n#   esquisser()"
  },
  {
    "objectID": "posts/encuestas/index.html#ejemplo-monitor-socioeconómico",
    "href": "posts/encuestas/index.html#ejemplo-monitor-socioeconómico",
    "title": "Procesando datos de encuestas Con R",
    "section": "Ejemplo: monitor socioeconómico",
    "text": "Ejemplo: monitor socioeconómico\nEs un tablero creado completamente en R que extrae los microdatos de la Encuesta Permanente de Hogares (INDEC), los procesa y visualiza de manera dinámica para conocer más sobre la coyuntura e historia reciente del mercado de trabajo y condiciones de vida en Argentina.\nSe trata de un proyecto en progreso del NIS que da cuenta de cómo podemos usar las nuevas herramientas de análisis y programación para automatizar y comunicar nuestro trabajo."
  },
  {
    "objectID": "posts/encuestas/index.html#bonus",
    "href": "posts/encuestas/index.html#bonus",
    "title": "Procesando datos de encuestas Con R",
    "section": "Bonus",
    "text": "Bonus\nLa lógica de visualización no es solo para datos, ubicando puntos en los ejes x e y también podremos dibujar:\n\n\nVer código\nseq(-2,2, by = 0.01) %>% \n  expand.grid(x=., y=.) %>% \n  ggplot(aes(x = x^3 - sin(y), y = y^3 - cos(x)))+\n  geom_point(alpha = 0.05, \n             color = \"#5E17EB\", shape = 20, size = 0)+ #https://www.color-hex.com/\n  theme_void()+\n  coord_polar()+\n  labs(subtitle = \"Llegamos al final de esta experiencia, gracias por participar\")\n\n\n\n\n\nHasta la próxima!"
  },
  {
    "objectID": "posts/genart/index.html",
    "href": "posts/genart/index.html",
    "title": "Una aproximación al arte generativo con R",
    "section": "",
    "text": "El arte generativo, también conocido en la actualidad como arte algorítmico, es un tipo de expresión visual que puede ser recreada digitalmente, estableciendo un diálogo difuso entre los campos del arte y la programación.\nA menudo un sentido común extendido asocia el arte al cauce de la expresión emocional de las personas, mientras que el acto de programar es emparentado a fríos códigos y lógicas pragmáticas que conducen a un resultado puntual. El arte generativo, creado por medio de algoritmos, tensa estas creencias siendo ambas cosas y ninguna de ellas. Pondremos aquí en juego herramientas rígidas y lógicas que crean algo asbtracto, impredecible e inesperado.\nEs dable destacar que las bases de la propuesta estética fueron establecidas en el Manifiesto Arte Generativo(https://noticiasrecoleta.com.ar/el-arte-generativo-y-sus-60-anos-exposicion-de-obras-en-el-museo-de-arte-moderno/) por los artistas argentinos Eduardo Mac Entyre y Miguel Ángel Vidal ( foto ) donde se proclamaba el espacio como un campo abierto a las tensiones de formas orbitales, trayectorias proyectadas y planos fugados en profundidad.\n\n\nManos a la obra\nConsidero significativo adentrarse a este tema por su relevancia histórico-cultural, destacando además su dimensión práctica, toda vez que en el proceso de desarrollo de estos objetos, podemos experimentar e involucrarnos con diversas lógicas, formas y colores, una caja de herramientas distinta (pero no tanto) a la que habitualmente utilizamos en nuestra rutina laboral y que nos permite expandir creativamente nuestras habilidades al momento de visualizar fenómenos con R.\n\n\nVer código\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(viridis)\nlibrary(ggplot2)\n\n\nPara situarnos en el espacio que nos propone R, comenzamos haciendo algo que ya conocemos: un ggplot de puntos en un plano con colores y formas. En términos generales, esta es una de las lógicas subyacentes de la visualización y nos permite tomar una dimensión de las potencialidades de nuestras herramientas.\n\n\nVer código\ndata <- data.frame(a1 = 1:5,# ej\na2 = 1:5)\nggplot(data, aes(a1, a2)) + # ggplot\ngeom_point(col = ifelse(1:nrow(data)==3, \n\"tomato\", \"orange\"),\nshape = ifelse(1:nrow(data)==3,15,16),\nsize = ifelse(1:nrow(data)==3,5,1))\n\n\n\n\n\nCrearemos ahora un espiral de arquímedes para ver qué pasa con ggplot cuando vamos mas allá de las rectas:\n\n\nVer código\n# crea un fondo blanco para el grafico\nopt = theme(legend.position  = \"none\",\npanel.background = element_rect(fill=\"#f0eaf7\"),\naxis.ticks = element_blank(),\npanel.grid = element_blank(),\naxis.title = element_blank(),\naxis.text = element_blank())\n# parametros\na <- 2\nb <- 3\ntheta <- seq(0,50*pi,0.05)\nr <- a + b*theta\ndf <- data.frame(x=r*cos(theta), \ny=r*sin(theta)) #coord\n#objeto ggplot\nggplot(df, aes(x,y)) + \ngeom_path(col='purple') + \nopt\n\n\n\n\n\nLuego de esta sucinta inmersión en la lógica de la visualización de elementos, indagaremos en las posibilidades que abren ggplot junto a dos paquetes que complementan las herramientas gráficas disponibles en R, y fueron desarrollados específicamente para la creación ( o producción?) de arte generativo y como veremos nos entregarán resultados más qué interesantes.\n\n\nggplot\n\n\nVer código\npolar_art <- function(seed, n, palette) {\n  \n  # semilla de generacion\n  set.seed(seed)\n  \n  # data frame con valores random de\n  # aesthetics que elegimos\n  dat <- tibble(\n    x0 = runif(n),\n    y0 = runif(n),\n    x1 = x0 + runif(n, min = -.2, max = .2),\n    y1 = y0 + runif(n, min = -.2, max = .2),\n    shade = runif(n), \n    size = runif(n)\n  )\n  \n  # grafica segmentos en varios colores, \n  # usando coordenadas polares y una paleta\n  dat |> \n    ggplot(aes(\n      x = x0,\n      y = y0,\n      xend = x1,\n      yend = y1,\n      colour = shade,\n      size = size\n    )) +\n    geom_segment(show.legend = FALSE) +\n    coord_polar() +\n    scale_y_continuous(expand = c(0, 0)) +\n    scale_x_continuous(expand = c(0, 0)) + \n    scale_colour_gradientn(colours = palette) + \n    scale_size(range = c(0, 10)) + \n    theme_void()\n}\n\npolar_art(seed = 1, n = 1000, palette = c(\"#e86af0\", \"#493267\", \"#7bb3ff\"))\n\n\n\n\n\nRepitamos para armar una secuencia con patchwork.\n\n\nVer código\nsample_data <- function(seed = NULL, n = 1000){\n  if(!is.null(seed)) set.seed(seed)\n  dat <- tibble(\n    x0 = runif(n),\n    y0 = runif(n),\n    x1 = x0 + runif(n, min = -.2, max = .2),\n    y1 = y0 + runif(n, min = -.2, max = .2),\n    shade = runif(n), \n    size = runif(n),\n    shape = factor(sample(0:22, size = n, replace = TRUE))\n  )\n}\n\npolar_styled_plot <- function(data = NULL, palette) {\n  ggplot(\n    data = data,\n    mapping = aes(\n      x = x0,\n      y = y0,\n      xend = x1,\n      yend = y1,\n      colour = shade,\n      size = size\n    )) + \n    coord_polar(clip = \"off\") +\n    scale_y_continuous(\n      expand = c(0, 0),\n      limits = c(0, 1), \n      oob = scales::oob_keep\n    ) +\n    scale_x_continuous(\n      expand = c(0, 0), \n      limits = c(0, 1), \n      oob = scales::oob_keep\n    ) + \n    scale_colour_gradientn(colours = palette) + \n    scale_size(range = c(0, 5)) + \n    theme_void() + \n    guides(\n      colour = guide_none(),\n      size = guide_none(),\n      fill = guide_none(),\n      shape = guide_none()\n    )\n}\n\nsample_canva <- function(seed = NULL) {\n  if(!is.null(seed)) set.seed(seed)\n  sample(ggthemes::canva_palettes, 1)[[1]]\n}\n\ndat <- sample_data(n = 1000, seed = 1) |>\n  mutate(y1 = y0, size = size / 10)\n\np1<-polar_styled_plot(palette = sample_canva(seed = 8)) + \n  geom_segment(data = dat, linetype = \"1111\") \n\n\np2<-polar_styled_plot(palette = sample_canva(seed = 10)) + \n  geom_segment(data = dat, linetype = \"11112266\") \n\n\np3<-polar_styled_plot(palette = sample_canva(seed = 500)) + \n  geom_segment(data = dat, linetype = \"15\") \n\nlibrary(patchwork)\n\np1+p2+p3\n\n\n\n\n\n\n\nflametree\nflametree provee un sistema de funciones y sistemas de trabajo orientados a crear arboles con código y fomentar la experimentación con este tipo de formas expresivas.\n\n\nVer código\nlibrary(flametree)\n\n# elegimos nuestros colores\nshades <- c(\"#c79dd7\", \"#ef4f91\", \"#c5b9cd\", \"#abb1cf\")\n\n#ef4f91 (239,79,145)\n#c79dd7 (199,157,215)\n#4d1b7b (77,27,123)\n\n# definimos los datos con los que se van a generar los arboles\ndat <- flametree_grow(time = 10, trees = 10)\n\n# graficamos\ndat %>% \n  flametree_plot(\n    background = \"antiquewhite\",\n    palette = shades, \n    style = \"nativeflora\"\n  )\n\n\n\n\n\nVeamos otro con una estética ciberpunk:\n\n\nVer código\njittr <- function(coord_x, coord_y, id_tree, id_time) {\n  stats::runif(n = length(coord_x), min = -.2, max = .2)\n}\n\nflametree_grow(\n  time = 12,\n  seg_wid = spark_linear(constant = .2),\n  shift_x = jittr,\n  shift_y = jittr\n) %>% \n  flametree_plot(\n    palette = c(\"#bd00ff\", \"#f1dfec\"),\n    style = \"wisp\"\n  )\n\n\n\n\n\n\n\ncontouR\nSe trata de un paquete para modelar formas en articulación con ggplot, si bien es limitado en funcionalidad, la propuesta de paquete se basa en la modidicación de parámetros para construir la imagen final.\n\n\nVer código\nlibrary(contouR)\n\n#set up your data\nsetup = contour_grid(grid_size = 100, point_dist = .25, \n             z_method = \"runif\", z = 10, z_span = 10) %>%\n  contour_shape(radius = 15, \n                x_center = 7, y_center = 9) \n\n# plot your data\ncontour_plot(setup$grid_shape) +\n  ggplot2::xlim(1, 30) +\n  ggplot2::ylim(1, 30)\n\n\n\n\n\nSe parece a un planeta hecho crochet no?\n\n\naRtsy\nSi la broma te dió risa…¿Qué diferencia hay si fue creada por un algoritmo?” (Marcus du Sautoy, El código creativo )\nAsí comienza Artsy su blog y nos presenta una serie de funcionalidades para crear nuestro obra generativa de forma simple y al alcance de todos y todas. El paquete proporciona varios algoritmos para crear proyecciones ggplot que incorporan aleatoriedad (según la seed) y, de los 3 que vimos, es mi favorito, con lo cual me gustaría profundizar más en él.\nAntes de comenzar a utilizar este paquete es importante saber que el mismo se organiza en colecciones, cada una genera un tipo de proyección o forma distinta.\nLa función canvas_strokes() permite, por ejemplo, simular el trazo de un pincel ejecutando un calculo de probablilidad en la que todos los puntos de la proyección tienen la probabilidad de adquirir el color del punto próximo, pero también incorpora una pequeña posibilidad de asumir un color distinto.\n\n\nVer código\nlibrary(aRtsy)\nset.seed(5)\n#colores de la paleta de referencia. \n#https://www.color-hex.com/color-palette/84832\ncanvas_strokes(colors = \nc('#e8d0d9', '#e590a5', \n'#75638b', '#507592',\n'#dac291'), \nneighbors = 1, p = 0.005, \niterations = 10, \n#width = 500, height = 500, \nside = FALSE)\n\n\n\n\n\nEs el caso de canvas_squares, que utiliza una variedad de cuadrados y rectángulos en lugar de líneas. Funciona cortando repetidamente el lienzo en ubicaciones aleatorias y coloreando el área que crean estos cortes:\n\n\nVer código\nlibrary(aRtsy)\nset.seed(6)\ncanvas_squares(colors = c(\n'#fac901', '#ffffff', \n'#225095', '#dd0100'),\ncuts = 50, ratio = 2.5, \n#width = 100, height = 100\n)\n\n\n\n\n\nVer código\n#paleta de referencia\n#https://www.color-hex.com/color-palette/25374\n\n\nTambién resultan atractivas las proyecciones de canvas_ribbons() que mantiene la lógica anterior, pero utiliza cintas y triángulos conectados a través de nodos comunes.\n\n\nVer código\nset.seed(784)\ncanvas_ribbons(colors = \nc('#CC102D', \n'#E88514', '#FFFF28', \n'#7DC62C', '#71C0DE',\n'#634C8A'),\nbackground = '#1c2117', \ntriangle = TRUE)\n\n\n\n\n\nVer código\n# referencia de la paleta \n#  https://www.schemecolor.com/the-dark-\n#  side-of-the-moon-pink-floyd-colors.php\n#  lo intente!\n\n\nFinalmente, la colección Supervised trabaja con funciones de agrupación supervisadas propias del machine learning. Los algoritmos de esta colección funcionan generando puntos de datos aleatorios en un plano bidimensional (con una variable de respuesta continua o categórica). Posteriormente la modelan utilizando el algoritmo de aprendizaje supervisado.\nPara el caso concreto del cuadro de mosaicos que sigue operaremos de fondo con un algoritmo k means:\n\n\nVer código\ncanvas_mosaic(colors = \nc(\"#ff598f\",    \n\"#fd8a5e\",\n\"#e0e300\",\n\"#01dddd\",\n\"#00bfaf\"),\nn = 25,resolution = 1000)\n\n\n\n\n\nVer código\n# paleta de referencia\n# https://www.color-hex.com/color-palette/63466\n\n\n\n\nConclusión\nEsta fue una selección de experiencias y posibilidades experimentando con el denominado arte generativo en R, los códigos abiertos de este post y las referencias citadas invitan a lxs interesadxs a replicar-reconfigurar las imágenes propuestas.\nLas primeras impresiones de quien escribe con respecto al arte generativo es que en tanto técnica expresiva estimula creativamente a indagar y conocer más sobre el procesamiento de imágenes y la proyección de datos en R.\nEn este sentido podremos afirmar que arte generativo es una interesante alternativa para quienes quieran programar recrativamente, explorar las posibilidades de formas, colores y espacios que tenemos a disposición en r, procastinar en horario de trabajo o estudio, crear objetos artísticos (eventualmente venderlos a precio justo, recomiendo indagar en que qué es un nft ), todas las anteriores o ninguna, pero siempre con el mismo sentimiento compartido: el amor al arte💜 .\n\n\n\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{damiánorden2022,\n  author = {Pedro Damián Orden},\n  editor = {},\n  title = {Una Aproximación Al Arte Generativo Con {R}},\n  date = {2022-09-24},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPedro Damián Orden. 2022. “Una Aproximación Al Arte Generativo Con\nR.” September 24, 2022."
  },
  {
    "objectID": "posts/presion/index.html",
    "href": "posts/presion/index.html",
    "title": "Python y R en Quarto con la Encuesta Permanente de Hogares",
    "section": "",
    "text": "Sobre el mercado de trabajo\nAl relevar de manera periódica la realidad socioeconómica argentina, la EPH es un gran insumo para conocer los principales indicadores5 sobre el mercado de trabajo y analizar su evolución en el tiempo.\nPara dar con un proceso significativo de la dinámica del mercado laboral, nos enfocaremos en este caso en aquellos grupos de personas que no tienen empleo, están disconformes con el que tienen, o bien desean trabajar más horas, lo que operativamente son reflejados por los “indicadores de presión”6.\nDe esta forma, re-construiremos con datos de la EPH la variable de presión general sobre el mercado de trabajo, para visualizar en nuestro documento cómo un segmento de la PEA puja por mayor participación en el mercado laboral, ya sea demandando trabajar más horas o bien buscando un nuevo empleo7.\nEste caso será una buena y sucinta oportunidad para conocer cómo funciona Quarto y estimular la posibilidad de incorporar e integrar lenguajes para el análisis de datos en las ciencias sociales .\nTomaremos como referencia comparativa con nuestro código los datos que provee el informe técnico / Vol. 6, n° 54: Mercado de trabajo. Tasas eindicadores socioeconómicos (EPH) 8.\n\n\nETL con Python\nEl trabajo inicial de ETL lo llevaremos adelante en Python9 dado que nos va a resultar más rápido que con R.\nPara la recopilación de microdatos utilizaremos la librería pyeph de reciente lanzamiento y que sus creadores/as presentan de la siguiente forma:\n\n“La librería Pyeph tiene como objetivo facilitar el procesamiento en Python de la Encuesta Permanente de Hogares. Está pensada como un espacio donde se nuclean y centralizan los cálculos vinculados a las mismas para posteriormente ser utilizadas en investigaciones, artículos, publicaciones, etc. Es una librería que hace principal hincapié en la transparencia metodológica utilizando licencias de código abierto y que promueve la colaboración de las comunidades de cientístas de datos, sociales, investigadorxs, desarrolladorxs, periodistas y demás curiosxs”.\n\nVamos entonces a instalar la librería y nos descargaremos el set completo de datos de la encuesta para 2021, no sin antes saber algo importante en Quarto; para construir un bloque de código que ejecute el lenguaje que nos interesa utilizar, primero hay que declararlo.\n\n\nVer código\n#En este caso declaramos un bloque de {python}\n\n#instalamos la libreria de python pyeph\n#!pip install pyeph\n\n#la instalacion esta grisada porque en mi caso la libreria ya está descargada\n\n\nLlamamos a pyeph y descargamos los datos.\n\n\nVer código\nimport pyeph\neph1 = pyeph.obtener(data=\"eph\", ano=2021, periodo=1, tipo_base='individual') # EPH individual\n\n\nVer código\neph2 = pyeph.obtener(data=\"eph\", ano=2021, periodo=2, tipo_base='individual') # EPH individual\n\n\nVer código\neph3 = pyeph.obtener(data=\"eph\", ano=2021, periodo=3, tipo_base='individual') # EPH individual\n\n\nVer código\neph4 = pyeph.obtener(data=\"eph\", ano=2021, periodo=4, tipo_base='individual') # EPH individual\n\n\nSeguidamente importaremos pandas y formatearemos los datos necesarios para nuestro análisis.\n\n\nVer código\n# !pip install pandas\nimport pandas as pd\n# consturimos nuestro dataframefinal\ndatosehp = pd.concat([eph1, eph2, eph3, eph4])\n# Nos quedamos con las variables que nos interesan, son 5.\ndatosehp = datosehp[[\"TRIMESTRE\", \"PONDERA\", \"ESTADO\", \"PP03J\", \"PP03H\"]]\n#guardamos los datos a un csv\ndatosehp.to_csv('eph2021.csv')\n\n\n\n\nAjustes y primeras visualizaciones en R\nUna vez que llegamos a este punto, vamos a abrir un bloque de código en R para dar forma acabada a nuestro proyecto. Para ello descargamos el archivo csv con los datos que construimos y guardamos más arriba.\n\n\nVer código\neph2021<-read.csv(\"eph2021.csv\")\n\n\nLlamamos a la libería tidyverse para darle la forma final a nuestro dataframe.\n\n\nVer código\nlibrary(tidyverse)\n\n\nAgruparemos los datos por cuatrimestre y les aplicaremos una serie de funciones para identificar ocupados, desocupados, PEA, ocupados demandantes y disponibles. De esta forma podremos también construir las tasas de desocupación abierta, ocupados demandantes, ocupados no demandantes disponibles, ocupados no disponibles y el porcentual resultante de presión sobre el mercado de trabajo.\n\n\nVer código\npresion_ar <- eph2021 %>% \n  group_by(TRIMESTRE) %>% \n  summarise(ocupados = sum(PONDERA[ESTADO == 1]),\n            desocupados = sum(PONDERA[ESTADO == 2]),\n            PEA = ocupados + desocupados,\n            ocupados_demand = sum(PONDERA[ESTADO == 1 & PP03J ==1]),\n            ocupados_disp = sum(PONDERA[ESTADO == 1 & PP03J ==2 & PP03H %in% c(1,2,9)]),\n            `desocupacion abierta` = desocupados/PEA*100,\n            `ocupados demandantes` = ocupados_demand/PEA*100,\n            `ocup. no demandantes disponibles` = ocupados_disp/PEA*100,\n            `ocupados no disponibles` = 100-c(`desocupacion abierta`+`ocupados demandantes`+`ocup. no demandantes disponibles`),\n            `presion sobre el mercado laboral` = `desocupacion abierta`+`ocupados demandantes`+`ocup. no demandantes disponibles`)%>%\n  ungroup()%>%\n  mutate_if(is.numeric, round, digits=2)%>%\n  mutate(\n         TRIMESTRE=as.factor(TRIMESTRE))%>%\n  select(TRIMESTRE,\n         'desocupacion abierta',\n         'ocupados demandantes',\n         'ocup. no demandantes disponibles',\n         'ocupados no disponibles',\n         'presion sobre el mercado laboral')\n\n\nCreemos y visualicemos una tabla con los resultados en gt().\n\n\n\n\n\n\n  \n    \n      Resumen de tasas seleccionadas de de Mercado de Trabajo\n    \n    \n      Datos porcentuales para los 4 trimestres de 2021.\n    \n  \n  \n    \n      Tasas\n      1er trimestre\n      2do trimestre\n      3er trimestre\n      4to trimestre\n    \n  \n  \n    desocupacion abierta\n10.16\n9.60\n8.24\n6.97\n    ocupados demandantes\n16.53\n16.97\n16.47\n17.38\n    ocup. no demandantes disponibles\n5.72\n5.84\n6.67\n6.13\n    ocupados no disponibles\n67.59\n67.59\n68.62\n69.53\n    presion sobre el mercado laboral\n32.41\n32.41\n31.38\n30.47\n  \n  \n    \n      Fuente: elaboración propia en base a datos de la EPH (INDEC).\n    \n  \n  \n\n\n\n\nY ahora comparémoslos con los datos que provee el INDEC en el informe que tomamos como referencia.\n\nBastante parecido verdad? De haber redondeado el segundo decimal hubieramos estado prácticamente iguales!\nGrafiquemos ahora los datos con ggplot2. Primero el desagregado problacional de la PEA que presiona sobre el mercado de trabajo.\n\n\nVer código\n#install.packages(\"glue\")\n\nlibrary(glue) #glue es una libreria util para pegar texto\n\npresion_ar2 <- presion_ar %>%\n    gather('Indicador', 'valor', c(2:6)) %>%\n    arrange(desc(valor))%>%\n    unique()%>%\n    ungroup()\n\ntotal<-presion_ar2%>%\n  filter(Indicador==\"presion sobre el mercado laboral\")\n\np1<-presion_ar2 %>%\n filter(!(Indicador %in% c(\"ocupados no disponibles\", \"presion sobre el mercado laboral\"))) %>%\n ggplot() +\n aes(x = TRIMESTRE, y = valor, fill = Indicador) +\n geom_col(alpha=0.7) +\n scale_fill_manual(values = c(`desocupacion abierta` = \"#F0AF5C\",\n                               `ocup. no demandantes disponibles`='#5C9DF0',\n                               `ocupados demandantes` = \"#1A69D2\"))+\n  geom_label(aes(label = glue(\"{round(valor,digits=1)} %\"), y=valor), \n               size = 3.1, hjust = 0.5, vjust = 1, \n               fontface = \"bold\", colour=\"white\", \n               position = \"stack\", show.legend = FALSE)+\n  geom_text(data = total,\n            aes(x = TRIMESTRE,\n                y = valor,\n                label = paste0(\"Presión total: \\n\", valor, \" %\")),\n            colour=\"#1F4B72\",\n            size = 3,\n            fontface = \"bold\", \n            hjust = 0.5,\n            vjust=-0.1,\n            inherit.aes = FALSE,\n            show.legend = FALSE) +\n  labs(x = \"Trimestre\", \n      y = \"% de la PEA\", \n      title = \"  Grupos de población económicamente activa \nsegún tipo de presión sobre el mercado de trabajo\",\n      subtitle = \"Porcentuales para los 4 trimestres de 2021.\", \n      caption = \"Elaboración propia en base a datos de la EPH INDEC.\", \n      fill = \"tasa:\") +\n  coord_cartesian(ylim = c(0, 50))+\n  theme_classic() +\n  theme(legend.position = \"bottom\")\n\np1\n\n\n\n\n\nFinalmente, veamos la película completa, armando un panorama general de cómo es la distribución entre la tasa de ocupados no disponibles y la presión sobre el mercado de trabajo en los 4 trimestres de 2021 para el total de los 31 aglomerados que componen la EPH.\n\n\nVer código\np2 <- presion_ar2 %>%\n  filter((Indicador %in% c(\"ocupados no disponibles\", \n                           \"presion sobre el mercado laboral\"))) %>%\n  ggplot() +\n  aes(x = TRIMESTRE, y = valor, fill = Indicador) +\n  geom_col(position = position_stack(reverse = TRUE), alpha=0.6) +\n  scale_fill_manual(values = c(`ocupados no disponibles` = \"#63C3C5\",\n                               `presion sobre el mercado laboral` = \"#FF8B60\"))+\n  geom_label(aes(label = glue(\"{round(valor,digits=1)} %\"), y=valor), \n               size = 3.1, hjust = 0.5, vjust = 1, \n               fontface = \"bold\", colour=\"white\", \n               position = position_stack(reverse = TRUE), \n             show.legend = FALSE)+\n  labs(x = \"Trimestre\", \n      y = \"% de la PEA\", \n      title = \"Tasa de presión general sobre el mercado de trabajo.\",\n      subtitle = \"Porcentuales para los 4 trimestres de 2021.\", \n      caption = \"Elaboración propia en base a datos de la EPH INDEC.\", \n      fill = \"tasa:\") +\n  theme_classic() +\n  theme(legend.position = \"bottom\")\n\np2\n\n\n\n\n\nCon respecto a los datos y objetos gráficos que creamos se prefigura que la presión sobre el mercado de trabajo tendió a reducirse durante el año 2021 lo cual sería a propiori un dato positivo. Esta primera impresión deberá ser analizada en el marco de otros análisis para conocer sus implicancias concretas en la realidad socioeconómica nacional.\nPara acceder a los datos del mercado de trabajo en una serie de tiempo más amplia y en formato interactivo puede consultarse el monitor socioeconómico de mi autoría.\n\n\nConcluciones:\n\nEn Quarto la mezcla no es sinónimo de amontonamiento. La posibilidad amigable de integrar varios lenguajes de progamación en procesos de analítica y modelado de datos en ciencia sociales escala las opciones para hacer y conocer.\nAl respecto se seguirá resaltando que las tecnologías de programación y procesamiento de datos que hoy tenemos a disposición como profesionales10 nos permiten automatizar y/o resolver tareas complejas, reducir tiempos de entrega y costos, hechos que hasta hace poco tiempo resultaban impensables. Es indispensable tomar contacto con la técnica contemporánea, conocer cuales sos sus prestaciones e indagar con criterio profesional el hecho de si pueden o no ayudarnos a resolver problemas de nuestra rutina de trabajo.\nQuarto puede ser pensado mas allá de la plataforma de publicación, como un util secuenciador de nuestros flujos de trabajo, para ordenar fragmentos concretos de nuestro código y articular lenguajes de programación distintos sin tener que perder tiempo en configurar mayores cuestiones.\nAlgo que no es una conclusión pero no he no mencionado anteriormente es que Quarto es muy parecido a Rmarkdown y para quienes vienen usando esta plataforma el pasaje va a ser relativamente sencillo.\nDe la breve experiencia aquí presentada emerge una gran pregunta que tiene que ver con las (nuevas?) formas en que se construyen ciertos saberes contemporáneos. En el campo de las ciencias sociales y el desarrollo computacional la combinación criteriosa de teorías, métodos y lenguajes de programación se prefiguran como una potente estrategia de trabajo para abordar la compleja gama de realidades epocales en las que discurrimos como profesionales.\n\n\n\n\n\n\nFootnotes\n\n\nPara conocer más https://jasoncausey.net/post/quarto_early_impressions/↩︎\nAquí podrá consultarse como se configura.↩︎\nEn un encuadre más amplio puede pensarse también como un flujo de trabajo en el cual vamos encadenando acciones para llegar a responder un problema, independientemente de los lenguajes, formatos o publicaciones.↩︎\nAbarca 31 aglomerados urbanos donde habita, aproximadamente, el 70% d e la población urbana del país. Cubre todas las capitales de provincia y aglomerados urbanos de más de 100 mil habitantes. Más sobre la EPH: https://www.indec.gob.ar/indec/web/Institucional-Indec-BasesDeDatos↩︎\nEn este apartado INDEC sube los principales materiales relacionados al tema: https://www.indec.gob.ar/indec/web/Nivel4-Tema-4-31-58↩︎\nA propósito de la noción de presión sobre el mercado laboral, comúnmente se presupone que la población con una inserción insuficiente en el mercado de trabajo es la de los desocupados, por sus características específicas de no contar con una ocupación y buscarla de manera activa. No obstante, dicho proceso de búsqueda se verifica únicamente dentro de otros grupos poblacionales. Habida cuenta de los elevados niveles de desocupación y su prolongación en el tiempo, que caracterizan la historia reciente argentina, de manera frecuente las personas aceptan trabajos que si bien no se adaptan a sus expectativas de vida, les permiten obtener un ingreso en el mientras tanto y continuar en la búsqueda de un mejor horizonte laboral.↩︎\nPara profundizar más en indicadores sobre empleo y su medición se invita a conocer el trabajo de E Actis Di Pasquale de 2005: Condiciones Críticas de Empleo. Una Nueva Perspectiva de la Cuestión Laboral.↩︎\nINDEC. Recoge los datos completos de la serie 2021.↩︎\nSi esa primera vez que oís hablar de este lenguaje para descargar y configurarlo en tu pc quizás te sirva este video.↩︎\nEste articulo piensa en el caso particular de las ciencias humanas, pero esta abierto a cualquier otra identificación homóloga.↩︎\n\nReusehttps://creativecommons.org/licenses/by/4.0/CitationBibTeX citation:@online{damianorden2022,\n  author = {Pedro Damian Orden},\n  editor = {},\n  title = {Python y {R} En {Quarto} Con La {Encuesta} {Permanente} de\n    {Hogares}},\n  date = {2022-09-06},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nPedro Damian Orden. 2022. “Python y R En Quarto Con La Encuesta\nPermanente de Hogares.” September 6, 2022."
  },
  {
    "objectID": "posts/sport/socc.html",
    "href": "posts/sport/socc.html",
    "title": "Sports Analytics con R: explorando datos de Fútbol",
    "section": "",
    "text": "Durante los últimos años, en el campo de la ciencia de datos las denominadas sports analytics (analítica de datos deportivos) ha ganado cierta relevancia, dada 1) la progresiva tendencia hacia la profesionalización de los deportes masivos, 2) las nuevas de tecnologías de captura de datos disponibles, 3) la incorporación de expertos en tecnologías de la información en equipos y medios de comunicación, 4) la expansión a escala global de los mercados de jugadores, y 5) el auge de las apuestas en línea, entre los procesos mas destacables, y con ello han emergido progresivamente nuevos campos de saber basados en la evidencia y el deporte que pueden proporcionar a quien los analice y modelice una ventaja competitiva para con sus rivales.\nLas posibles entradas a la temática son múltiples, por lo que la invitación aquí es a explorar las posibilidades que brinda R en general para trabajar con datos, y en particular, para analizar una gama amplia información proveniente de deportes de alta competencia.\nEspecíficamente, utilizaremos técnicas EDA aplicadas a datos del fútbol nacional e internacional para dar nuestros primeros pasos en la escena de la analítica deportiva.\nComencemos."
  },
  {
    "objectID": "posts/sport/socc.html#recopilando-datos-de-fútbol",
    "href": "posts/sport/socc.html#recopilando-datos-de-fútbol",
    "title": "Sports Analytics con R: explorando datos de Fútbol",
    "section": "Recopilando datos de Fútbol",
    "text": "Recopilando datos de Fútbol\nComo muchos otros datos con los que trabajamos, los relacionados con fútbol no se encuentran dispuestos de manera ágil o sencilla para que podamos analizarlos, debemos capturarlos de alguna forma.\n\nEl paquete de referencia: worldfootballR\nPara obtener la data de las competencias y/o jugadores que sean pertinentes a los objetivos de nuestro análisis, utilizaremos worldfootballR, uno de los paquetes mas completos que existen en la actualidad sobre fútbol desarrollados por la comunidad de R.\nA lo largo de este documento veremos algunas de sus funcionalidades combinadas con técnicas de transformación de datos sobre casos concretos: el análisis de una liga, el scouting de un jugador o la exploración de la colección histórica de datos del mundial.\nCabe resaltar que el funcionamiento del paquete se basa en consultas a bases de datos de terceros. Para nuestro tutorial utilizaremos aquellas funciones que nos permiten conectarnos con las bases de FBREF, un portal de estadísticas de fútbol líder en el segmento. También pueden consultarse las bases de Transfermarkt, Understat y Fotmob.\n\n\nDescarga de los datos\nComenzamos instalando y levantando worldfootballR, junto al resto de paquetes de trabajo.\n\n## install.packages(\"worldfootballR\")\nlibrary(worldfootballR)\nlibrary(tidyverse)#para manipular nuestros datos\nlibrary(gt)#para hacer tablas\n\n\n\nApartado para jugadores\nPara requerir los datos individuales de Lionel Messi pasamos la función fb_player_season_stats al link del jugador en fbref y obtendremos un df con datos históricos sobre distintos tipos de incidencias en la carrera del astro argentino.\n\nmessi_stats <- fb_player_season_stats(\n  \"https://fbref.com/en/players/d70ce98e/Lionel-Messi\", \n  stat_type = 'standard') # se pueden elegir otro tipo de estadisticas, aquí elegimos las estándar, podriamos probar con 'misc'.\n\n#podemos guardar nuestros datos sobre messi en un excel si quisieramos\n#library(openxlsx)\n#write.xlsx(messi_stats, 'messi_stats.xlsx')\n\nExploramos nuestros datos con la función glimpse de tidyverse (dplyr)\n\nglimpse(messi_stats)\n\nRows: 54\nColumns: 32\n$ player_name                <chr> \"Lionel Messi\", \"Lionel Messi\", \"Lionel Mes~\n$ player_url                 <chr> \"https://fbref.com/en/players/d70ce98e/Lion~\n$ Season                     <chr> \"2004-2005\", \"2004-2005\", \"2005-2006\", \"200~\n$ Age                        <dbl> 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22,~\n$ Squad                      <chr> \"Barcelona\", \"Barcelona\", \"Barcelona\", \"Bar~\n$ Country                    <chr> \"\", \"ESP\", \"\", \"ESP\", \"\", \"ESP\", \"\", \"ESP\",~\n$ Comp                       <chr> \"1. Champions Lg\", \"1. La Liga\", \"1. Champi~\n$ MP                         <dbl> 1, 7, 6, 17, 5, 26, 9, 27, 12, 31, 11, 35, ~\n$ Starts_Time                <dbl> 1, 0, 4, 11, 4, 23, 9, 23, 10, 27, 11, 30, ~\n$ Min_Time                   <dbl> 90, 70, 322, 911, 385, 1983, 728, 1973, 927~\n$ Mins_Per_90_Time           <dbl> 1.0, 0.8, 3.6, 10.1, 4.3, 22.0, 8.1, 21.9, ~\n$ Gls                        <dbl> 0, 1, 1, 6, 1, 14, 6, 10, 9, 23, 8, 34, 12,~\n$ Ast                        <dbl> 0, 0, 1, 3, 0, 3, 2, 12, 5, 11, 0, 9, 3, 19~\n$ G_minus_PK                 <dbl> 0, 1, 1, 6, 1, 14, 5, 6, 9, 20, 8, 33, 11, ~\n$ PK                         <dbl> 0, 0, 0, 0, 0, 0, 1, 4, 0, 3, 0, 1, 1, 4, 4~\n$ PKatt                      <dbl> 0, 0, 0, 0, 0, 0, 1, 4, 0, 4, 0, 1, 2, 4, 5~\n$ CrdY                       <dbl> 0, 0, 0, 2, 1, 2, 2, 2, 1, 2, 0, 3, 0, 3, 2~\n$ CrdR                       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ Gls_Per_Minutes            <dbl> 0.00, 1.29, 0.28, 0.59, 0.23, 0.64, 0.74, 0~\n$ Ast_Per_Minutes            <dbl> 0.00, 0.00, 0.28, 0.30, 0.00, 0.14, 0.25, 0~\n$ `G+A_Per_Minutes`          <dbl> 0.00, 1.29, 0.56, 0.89, 0.23, 0.77, 0.99, 1~\n$ G_minus_PK_Per_Minutes     <dbl> 0.00, 1.29, 0.28, 0.59, 0.23, 0.64, 0.62, 0~\n$ `G+A_minus_PK_Per_Minutes` <dbl> 0.00, 1.29, 0.56, 0.89, 0.23, 0.77, 0.87, 0~\n$ xG_Expected                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ npxG_Expected              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ xAG_Expected               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ `npxG+xAG_Expected`        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ xG_Per_Minutes             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ xAG_Per_Minutes            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ `xG+xAG_Per_Minutes`       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ npxG_Per_Minutes           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ `npxG+xAG_Per_Minutes`     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n\n\nLas 32 variables del dataset recojen las principales estadísticas del jugador por temporada y competencia. Cabrá destacar que las mismas son sólo de partidos de Liga y Champions League, no incorporando por ejemplo datos sobre la Copa del Rey, competición que Lio disputó y ganó durante su estadía en el Barcelona.\nCon los datos disponibles, creamos un cuadro que resume, por temporada, los goles, pases, asistencias y penales convertidos por Lio en la liga doméstica de España:\n\nmessi_stats%>%\n  filter(Squad==\"Barcelona\" & Comp== \"1. La Liga\")%>%\n  select(Season, MP, Gls, Ast, PK)%>%\n  rename(Temporada=Season,\n         Partidos=MP, \n         Goles=Gls, \n         Asistencias=Ast, \n         Penales=PK)%>%\n  gt()%>%\n  tab_header(title = \"Lionel Messi en Barcelona\",\n             subtitle = \"Estadisticas por temporada en La Liga 2004-2021\")\n\n\n\n\n\n  \n    \n      Lionel Messi en Barcelona\n    \n    \n      Estadisticas por temporada en La Liga 2004-2021\n    \n  \n  \n    \n      Temporada\n      Partidos\n      Goles\n      Asistencias\n      Penales\n    \n  \n  \n    2004-2005\n7\n1\n0\n0\n    2005-2006\n17\n6\n3\n0\n    2006-2007\n26\n14\n3\n0\n    2007-2008\n27\n10\n12\n4\n    2008-2009\n31\n23\n11\n3\n    2009-2010\n35\n34\n9\n1\n    2010-2011\n33\n31\n19\n4\n    2011-2012\n37\n50\n16\n10\n    2012-2013\n32\n46\n11\n4\n    2013-2014\n31\n28\n11\n7\n    2014-2015\n38\n43\n18\n5\n    2015-2016\n33\n26\n14\n3\n    2016-2017\n34\n37\n9\n6\n    2017-2018\n36\n34\n12\n2\n    2018-2019\n34\n36\n13\n4\n    2019-2020\n33\n25\n21\n5\n    2020-2021\n35\n30\n9\n3\n  \n  \n  \n\n\n\n\nUn punto destacable de este paquete es que podemos acceder a datos muy puntuales, como por ejemplo todas aquellas incidencias relacionadas con las oportunidades de tiro de un jugador o jugadora por campeonato y/o temporada. Veamos a continuación el ratio de goles convertidos por la cantidad de tiros al arco pateados por Messi jugando en la Champions Legue entre 2004 y 2022.\n\nmessi_tiros <- fb_player_season_stats(\"https://fbref.com/en/players/d70ce98e/Lionel-Messi\", stat_type = 'shooting')\n\n#write.xlsx(messi_tiros, 'messi_tiros.xlsx')\n\n\ntiroschampion<-messi_tiros%>%\n  filter(Comp==\"1. Champions Lg\")\n  \nggplot(tiroschampion) +\n  aes(x = Season, y = G_per_SoT_Standard) +\n  geom_col(fill = \"#A8B9D9\") +\n  labs(\n    x = \"Temporada\",\n    y = \"goles/tiros al arco\",\n    title = \"Lionel Messi en la Champions League 2004/2022\",\n    subtitle = \"Ratio de goles convertidos por disparos al arcos\",\n    caption= \"T&S en base a datos de fbref.com. Año 2022.\") +\n  geom_text(aes(label=G_per_SoT_Standard))+\n  theme(axis.text.x = element_text(angle = 35))\n\n\n\n\nResulta significativa la efectividad de Messi en la última temporada no?\nPara concluir el apartado de datos individuales, avanzaremos en la creación de una comparativa, requiriendo en simultáneo datos sobre los minutos jugados por Messi y Ronaldo en la temporada 2022-2023, considerando los partidos de liga y copa internacional (Champions o UEFA dependiendiendo el caso). Nos interesa saber cómo llegan ambos al mundial de Qatar en lo que respecta a ritmo futbolístico y tiempo en cancha.\n\n#pasamos la funcion fb_player_season_stats al vector de messi y ronaldo.\njugadores <- fb_player_season_stats(player_url = c(\"https://fbref.com/en/players/d70ce98e/Lionel-Messi\", \"https://fbref.com/en/players/dea698d9/Cristiano-Ronaldo\"), stat_type = \"playing_time\")#datos de tiempo de juego\n\n\n#openxlsx::write.xlsx(jugadores, 'jugadores.xlsx')\n\n\njugadores%>%\n  filter(Season==\"2022-2023\")%>%\n  group_by(player_name)%>%\n  summarise(partidos_tot=sum(MP), \n            min_tot= sum(Min_Time),\n            min_prom= min_tot/partidos_tot)%>%\n    mutate_if(is.numeric, round, digits=1)%>%\n  gt()\n\n\n\n\n\n  \n  \n    \n      player_name\n      partidos_tot\n      min_tot\n      min_prom\n    \n  \n  \n    Cristiano Ronaldo\n14\n875\n62.5\n    Lionel Messi\n17\n1486\n87.4\n  \n  \n  \n\n\n\n\nEn una primera vista, podríamos decir que en los últimos tiempos Messi jugó más que Ronaldo, participando de más partidos y siendo parte de los mismos durante más tiempo.\n\n\nLigas y partidos\nOtra posibilidad que nos brinda el paquete es recopilar, fecha a fecha, los partidos de una liga particular y sus incidencias.\nPongamos nuestra atención en último torneo argentino de primera división. Para ello vamos a recopilar mediante la funcion fb_match_urls los links de fbref con los datos de los partidos y vamos a guardarlos en el objeto primera_division.\nAl objeto primera división podremos pedirle campos detallados de estadísticas de goles, tiros al arco, pases, posesión y más. En este caso requeriremos un summary, o resumen, del torneo. Para ello utilizaremos la función fb_advanced_match_stats.\n\nfb_match_urls recopila los links cada partido en la base de fbstats\nprimera_division <- fb_match_urls(country = \"ARG\", #liga arg\n                               gender = \"M\", #masculino\n                               season_end_year = 2022, #temporada\n                               tier=\"1st\")\n\n# #recuperamos las estadisticas avanzadas\n\nprimera_resumen <- fb_advanced_match_stats(match_url = primera_division,\n                                                       stat_type = \"summary\",\n                                                       team_or_player = \"team\")\n\n\nglimpse(primera)\n\nRows: 754\nColumns: 38\n$ League            <chr> \"Argentine Primera División\", \"Argentine Primera Div~\n$ Match_Date        <chr> \"2022-06-03\", \"2022-06-03\", \"2022-06-04\", \"2022-06-0~\n$ Matchweek         <chr> \"Argentine Primera División (Matchweek 1)\", \"Argenti~\n$ Home_Team         <chr> \"Barracas Central\", \"Barracas Central\", \"Tucumán\", \"~\n$ Home_Formation    <chr> \"4-2-3-1\", \"4-2-3-1\", \"4-4-2\", \"4-4-2\", \"3-4-1-2\", \"~\n$ Home_Score        <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1~\n$ Home_xG           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~\n$ Home_Goals        <chr> \"Iván Tapia (P) · 13&rsquor;\", \"Iván Tapia (P) · 13&~\n$ Home_Yellow_Cards <chr> \"2\", \"2\", \"6\", \"6\", \"1\", \"1\", \"1\", \"1\", \"2\", \"2\", \"1~\n$ Home_Red_Cards    <chr> \"0\", \"0\", \"1\", \"1\", \"1\", \"1\", \"0\", \"0\", \"0\", \"0\", \"0~\n$ Away_Team         <chr> \"CC Córdoba\", \"CC Córdoba\", \"Colón\", \"Colón\", \"Indep~\n$ Away_Formation    <chr> \"4-4-2\", \"4-4-2\", \"4-5-1\", \"4-5-1\", \"4-2-3-1\", \"4-2-~\n$ Away_Score        <dbl> 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 0, 0, 1, 1~\n$ Away_xG           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~\n$ Away_Goals        <chr> \"Renzo López · 77&rsquor;\", \"Renzo López · 77&rsquor~\n$ Away_Yellow_Cards <chr> \"5\", \"5\", \"4\", \"4\", \"2\", \"2\", \"3\", \"3\", \"2\", \"2\", \"2~\n$ Away_Red_Cards    <chr> \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0~\n$ Game_URL          <chr> \"https://fbref.com/en/matches/fa531c8b/Barracas-Cent~\n$ Team              <chr> \"Barracas Central\", \"CC Córdoba\", \"Tucumán\", \"Colón\"~\n$ Home_Away         <chr> \"Home\", \"Away\", \"Home\", \"Away\", \"Home\", \"Away\", \"Hom~\n$ Min               <dbl> 990, 990, 983, 990, 984, 990, 990, 990, 990, 990, 99~\n$ Gls               <dbl> 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1~\n$ Ast               <dbl> 0, 1, 1, 0, 1, 1, 0, 2, 0, 1, 0, 1, 1, 2, 1, 0, 1, 1~\n$ PK                <dbl> 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0~\n$ PKatt             <dbl> 2, 0, 0, 1, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0~\n$ Sh                <dbl> 9, 12, 19, 7, 11, 17, 12, 11, 11, 15, 15, 9, 13, 10,~\n$ SoT               <dbl> 5, 6, 4, 3, 3, 4, 3, 3, 6, 3, 7, 5, 2, 4, 5, 2, 5, 6~\n$ CrdY              <dbl> 2, 5, 5, 4, 1, 2, 1, 3, 2, 2, 1, 2, 2, 2, 3, 4, 2, 3~\n$ CrdR              <dbl> 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0~\n$ Fls               <dbl> 12, 20, 13, 13, 11, 7, 6, 15, 12, 10, 20, 17, 13, 15~\n$ Fld               <dbl> 19, 10, 10, 13, 7, 11, 14, 5, 9, 12, 17, 20, 14, 11,~\n$ Off               <dbl> 1, 3, 1, 0, 1, 2, 1, 0, 3, 0, 0, 1, 3, 0, 0, 4, 1, 3~\n$ Crs               <dbl> 21, 19, 27, 15, 26, 17, 26, 19, 27, 15, 19, 19, 36, ~\n$ TklW              <dbl> 10, 20, 13, 8, 9, 11, 8, 12, 11, 18, 21, 12, 9, 16, ~\n$ Int               <dbl> 11, 16, 13, 5, 8, 5, 12, 13, 17, 8, 9, 10, 17, 6, 4,~\n$ OG                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ PKwon             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~\n$ PKcon             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~\n\n\nLa cantidad de datos que nos proveemos con el campo de consulta summary es significativa. Hagamos una transformación de nuestro conjunto de datos para establecer el resultado de los partidos jugados por el club Boca Juniors según la condición de local y visitante.\n\nboca<-primera%>%\n  filter(Team==\"Boca Juniors\")%>% #filtamos el equipo\n  select(Match_Date, Home_Team, \n         Away_Team, Home_Score, \n         Away_Score, Home_Away)%>%\n  mutate(puntos_obtenidos=case_when(Home_Away==\"Home\" & Home_Score>Away_Score ~3,\n                           Home_Away==\"Home\" & Home_Score<Away_Score~0,\n                           Home_Away==\"Away\" & Home_Score>Away_Score~0,\n                           Home_Away==\"Away\" & Home_Score<Away_Score~3,\n                           Home_Score==Away_Score~1))\n\nPodremos preguntarnos cuantos puntos sacó Boca en el último torneo?\n\n#si!\nboca%>%\n  summarise(puntos=sum(puntos_obtenidos))\n\n  puntos\n1     52\n\n\nY cual fue la performance de Boca de local y visitante?\n\n#Tambien!\nlibrary(janitor)\n\nboca %>%\n  tabyl(Home_Away, puntos_obtenidos)%>%\n  adorn_totals(\"row\") %>%\n  adorn_percentages(\"row\") %>%\n  adorn_pct_formatting() %>%\n  adorn_ns() %>%\n  adorn_title(\"combined\")\n\n Home_Away/puntos_obtenidos         0         1          3\n                       Away 38.5% (5)  7.7% (1) 53.8%  (7)\n                       Home 14.3% (2) 21.4% (3) 64.3%  (9)\n                      Total 25.9% (7) 14.8% (4) 59.3% (16)\n\n\nPodremos observar que el equipo sumó más puntos de local ganando más partidos y perdiendo menos que de visitante.\nPor último grafiquemos la progresión de puntos obtenidos fecha a fecha por el conjunto de la rivera durante el último torneo.\n\nboca<-boca%>%\n  mutate(cumsum = cumsum(puntos_obtenidos), #puntos acumulados\n         fecha=as.Date(Match_Date))\n\nboca%>%\n  ggplot() +\n  aes(x = fecha, y = cumsum) +\n  geom_point(shape = \"circle\", size = 1.7, colour = \"#4682B4\") +\n  geom_line(size = 0.5, colour = \"steelblue\") +\n    scale_x_date(date_labels = \"%b/%d\", \n                 date_breaks= \"week\")+\n  labs(\n    x = \"Semana\",\n    y = \"Puntaje\",\n    title = \"Boca Juniors: Progresión de puntos obtenidos en la liga 2022\",\n    subtitle = \"Primera División.\",\n    caption = \"Tecnología y Sociedad en base a datos de FBStats. Año 2022\"\n  ) +\n  ggthemes::theme_stata()+\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\nHistorial de Mundiales\nComo último elemento de nuestra exploración con R en el campo de las sports analytics, utilizaremos la función load_match_comp_results para recuperar en un dataframe los resultados históricos de los mundiales femeninos de fútbol.\n\nmundiales_w <- load_match_comp_results(comp_name = \"FIFA Women's World Cup\")\n\n#openxlsx::write.xlsx(mundiales_w, 'mundiales_w.xlsx') \n\n\ndplyr::glimpse(mundiales_w)\n\nRows: 284\nColumns: 20\n$ Competition_Name <chr> \"FIFA Women's World Cup\", \"FIFA Women's World Cup\", \"~\n$ Gender           <chr> \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\"~\n$ Country          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ Season_End_Year  <dbl> 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991,~\n$ Round            <chr> \"Group stage\", \"Group stage\", \"Group stage\", \"Group s~\n$ Wk               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ Day              <chr> \"Sat\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Tue\", \"Tue~\n$ Date             <dbl> 33558, 33559, 33559, 33559, 33559, 33559, 33561, 3356~\n$ Time             <chr> \"20:45\", \"15:30\", \"19:45\", \"19:45\", \"19:45\", \"19:45\",~\n$ Home             <chr> \"China PR cn\", \"Germany de\", \"Japan jp\", \"Chinese Tai~\n$ HomeGoals        <dbl> 4, 4, 0, 0, 3, 2, 4, 1, 2, 0, 0, 0, 0, 0, 2, 4, 2, 0,~\n$ Home_xG          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ Away             <chr> \"no Norway\", \"ng Nigeria\", \"br Brazil\", \"it Italy\", \"~\n$ AwayGoals        <dbl> 0, 0, 1, 5, 0, 3, 0, 0, 2, 5, 8, 3, 3, 2, 0, 1, 1, 2,~\n$ Away_xG          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ Attendance       <dbl> 65000, 14000, 14000, 11000, 14000, 14000, 12000, 1200~\n$ Venue            <chr> \"Tianhe Stadium (Neutral Site)\", \"Jiangmen Stadium (N~\n$ Referee          <chr> \"Salvador Imperatore Marcone\", \"Rafael Rodriguez\", \"L~\n$ Notes            <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"~\n$ MatchURL         <chr> \"https://fbref.com/en/matches/0d9e0f26/China-PR-Norwa~\n\n\nCuantos goles se anotaron en lo mundiales femeninos torneo a torneo? Cómo evolucionó la cantidad de asistentes por torneo?\n\nmundiales_tidy <- mundiales_w%>%\n  select(Season_End_Year, HomeGoals, AwayGoals, Attendance)%>%\n  mutate(goles=HomeGoals+AwayGoals)%>%\n  group_by(Season_End_Year)%>%\n  summarise(goles_total=sum(goles),\n            asistentes=sum(Attendance, na.rm = TRUE))%>%\n  mutate(fecha=as.factor(Season_End_Year))%>%\n  select(!Season_End_Year)\n\nmundiales_tidy%>%\n  gt()\n\n\n\n\n\n  \n  \n    \n      goles_total\n      asistentes\n      fecha\n    \n  \n  \n    99\n515000\n1991\n    99\n112294\n1995\n    122\n1214215\n1999\n    105\n656789\n2003\n    111\n1176955\n2007\n    86\n248107\n2011\n    146\n1353486\n2015\n    146\n1095118\n2019\n  \n  \n  \n\n\n\n\nGrafiquemos nuestros resultados, vamos usar el eje Y para dar cuenta del público, y en un eje Y secundario para imprimir los datos de los goles.\n\nmundiales_tidy%>%\n  ungroup()%>%\n  ggplot() +\n  geom_bar(aes(x=fecha, y=asistentes), \n           stat=\"identity\", fill=\"#9BCD9B\", alpha=0.7, group = 1)+\n  geom_line(aes(x=fecha, y=goles_total*10000), size=1.2,\n            stat=\"identity\", color=\"#278AFC\", group = 2)+\n  geom_point(aes(x=fecha, y=goles_total*10000), size=2,\n            stat=\"identity\", color=\"#0364D4\", alpha=0.5 ,group = 2)+\n  labs(title= \"Espectadores y Goles por Mundial Femenino disputado\",\n       subtitle = \"Período 1991-2019.\",\n       x=\"Torneo\",\n       y=\"Espectadores\",\n       caption = \"T&S en base a datos de fbref.com. Año 2022.\")+\n  scale_y_continuous(sec.axis=sec_axis(~.*0.0001,\n                                       name=\"Goles\"))"
  },
  {
    "objectID": "posts/sport/socc.html#conclusiones",
    "href": "posts/sport/socc.html#conclusiones",
    "title": "Sports Analytics con R: explorando datos de Fútbol",
    "section": "Conclusiones",
    "text": "Conclusiones\nA lo largo de esta experiencia pudimos adentrarnos la múltiples posibilidades que nos brinda R para recopilar y explorar datos de fútbol utilizando el paquete worldfootballR. Llevando adelante técnicas EDA y de análisis descriptivo pudimos respondernos algunas preguntas sistematizando distintos conjuntos de datos descargados en cápsulas de información relevante, la materia prima que alimenta los procesos de analítica descriptiva.\nSerá destacable mencionar que este tipo de experiencias aplicadas no sólo son últiles para el análisis de procesos deportivos en sí, sino que además pueden volver mas cercanos aprendizajes relativos al procesamiento e indagación con datos, ya que se trata de técnicas amenas que constelan con abordajes de realidades gamificadas y cercanas, al ser por ejemplo el fútbol un deporte de gran impacto popular.\nEn suma, las sports analytics hoy son una realidad en el mundo del análisis y ciencia de datos, pueden ser una interesante puerta de entrada para quienes se están iniciando o una profesión rentable para los analistas profesionales…un momento…y el Mundial de Qatar 2022?\nContinuará."
  },
  {
    "objectID": "posts/sport/socc.html#bibliografía",
    "href": "posts/sport/socc.html#bibliografía",
    "title": "Sports Analytics con R: explorando datos de Fútbol",
    "section": "Bibliografía:",
    "text": "Bibliografía:\nExtracting data from FBref : https://jaseziv.github.io/worldfootballR/articles/extract-fbref-data.html\nFootball Analytics: Creating an xG-xGA comparison chart in R : https://www.invertedwinger.com/football-analytics-creating-an-xg-xga-comparison-chart-in-r/\nSport Analytics: A Review: https://www.academia.edu/73063599/Sport_Analytics_A_Review\nBig data and tactical analysis in elite soccer: future challenges and opportunities for sports science. https://springerplus.springeropen.com/articles/10.1186/s40064-016-3108-2"
  },
  {
    "objectID": "posts/sport/index.html",
    "href": "posts/sport/index.html",
    "title": "Sports Analytics con R: explorando datos de Fútbol",
    "section": "",
    "text": "## Propuesta\nDurante los últimos años, en el campo de la ciencia de datos las denominadas sports analytics (analítica de datos deportivos) ha ganado cierta relevancia, dada 1) la progresiva tendencia hacia la profesionalización de los deportes masivos, 2) las nuevas de tecnologías de captura de datos disponibles, 3) la incorporación de expertos en tecnologías de la información en equipos y medios de comunicación, 4) la expansión a escala global de los mercados de jugadores, y 5) el auge de las apuestas en línea, entre los procesos mas destacables, y con ello han emergido progresivamente nuevos campos de saber basados en la evidencia y el deporte que pueden proporcionar a quien los analice y modelice una ventaja competitiva para con sus rivales.\nLas posibles entradas a la temática son múltiples, por lo que la invitación aquí es a explorar las posibilidades que brinda R en general para trabajar con datos, y en particular, para analizar una gama amplia información proveniente de deportes de alta competencia.\nEspecíficamente, utilizaremos técnicas EDA aplicadas a datos del fútbol nacional e internacional para dar nuestros primeros pasos en la escena de la analítica deportiva.\nComencemos."
  },
  {
    "objectID": "posts/sport/index.html#recopilando-datos-de-fútbol",
    "href": "posts/sport/index.html#recopilando-datos-de-fútbol",
    "title": "Sports Analytics con R: explorando datos de Fútbol",
    "section": "Recopilando datos de Fútbol",
    "text": "Recopilando datos de Fútbol\nComo muchos otros datos con los que trabajamos, los relacionados con fútbol no se encuentran dispuestos de manera ágil o sencilla para que podamos analizarlos, debemos capturarlos de alguna forma.\n\nEl paquete de referencia: worldfootballR\nPara obtener la data de las competencias y/o jugadores que sean pertinentes a los objetivos de nuestro análisis, utilizaremos worldfootballR, uno de los paquetes mas completos que existen en la actualidad sobre fútbol desarrollados por la comunidad de R.\nA lo largo de este documento veremos algunas de sus funcionalidades combinadas con técnicas de transformación de datos sobre casos concretos: el análisis de una liga, el scouting de un jugador o la exploración de la colección histórica de datos del mundial.\nCabe resaltar que el funcionamiento del paquete se basa en consultas a bases de datos de terceros. Para nuestro tutorial utilizaremos aquellas funciones que nos permiten conectarnos con las bases de FBREF, un portal de estadísticas de fútbol líder en el segmento. También pueden consultarse las bases de Transfermarkt, Understat y Fotmob.\n\n\nDescarga de los datos\nComenzamos instalando y levantando worldfootballR, junto al resto de paquetes de trabajo.\n\n## install.packages(\"worldfootballR\")\nlibrary(worldfootballR)\nlibrary(tidyverse)#para manipular nuestros datos\nlibrary(gt)#para hacer tablas\n\n\n\nApartado para jugadores\nPara requerir los datos individuales de Lionel Messi pasamos la función fb_player_season_stats al link del jugador en fbref y obtendremos un df con datos históricos sobre distintos tipos de incidencias en la carrera del astro argentino.\n\nmessi_stats <- fb_player_season_stats(\n  \"https://fbref.com/en/players/d70ce98e/Lionel-Messi\", \n  stat_type = 'standard') # se pueden elegir otro tipo de estadisticas, aquí elegimos las estándar, podriamos probar con 'misc'.\n\n#podemos guardar nuestros datos sobre messi en un excel si quisieramos\n#library(openxlsx)\n#write.xlsx(messi_stats, 'messi_stats.xlsx')\n\nExploramos nuestros datos con la función glimpse de tidyverse (dplyr)\n\nglimpse(messi_stats)\n\nRows: 54\nColumns: 32\n$ player_name                <chr> \"Lionel Messi\", \"Lionel Messi\", \"Lionel Mes~\n$ player_url                 <chr> \"https://fbref.com/en/players/d70ce98e/Lion~\n$ Season                     <chr> \"2004-2005\", \"2004-2005\", \"2005-2006\", \"200~\n$ Age                        <dbl> 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22,~\n$ Squad                      <chr> \"Barcelona\", \"Barcelona\", \"Barcelona\", \"Bar~\n$ Country                    <chr> \"\", \"ESP\", \"\", \"ESP\", \"\", \"ESP\", \"\", \"ESP\",~\n$ Comp                       <chr> \"1. Champions Lg\", \"1. La Liga\", \"1. Champi~\n$ MP                         <dbl> 1, 7, 6, 17, 5, 26, 9, 27, 12, 31, 11, 35, ~\n$ Starts_Time                <dbl> 1, 0, 4, 11, 4, 23, 9, 23, 10, 27, 11, 30, ~\n$ Min_Time                   <dbl> 90, 70, 322, 911, 385, 1983, 728, 1973, 927~\n$ Mins_Per_90_Time           <dbl> 1.0, 0.8, 3.6, 10.1, 4.3, 22.0, 8.1, 21.9, ~\n$ Gls                        <dbl> 0, 1, 1, 6, 1, 14, 6, 10, 9, 23, 8, 34, 12,~\n$ Ast                        <dbl> 0, 0, 1, 3, 0, 3, 2, 12, 5, 11, 0, 9, 3, 19~\n$ G_minus_PK                 <dbl> 0, 1, 1, 6, 1, 14, 5, 6, 9, 20, 8, 33, 11, ~\n$ PK                         <dbl> 0, 0, 0, 0, 0, 0, 1, 4, 0, 3, 0, 1, 1, 4, 4~\n$ PKatt                      <dbl> 0, 0, 0, 0, 0, 0, 1, 4, 0, 4, 0, 1, 2, 4, 5~\n$ CrdY                       <dbl> 0, 0, 0, 2, 1, 2, 2, 2, 1, 2, 0, 3, 0, 3, 2~\n$ CrdR                       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ Gls_Per_Minutes            <dbl> 0.00, 1.29, 0.28, 0.59, 0.23, 0.64, 0.74, 0~\n$ Ast_Per_Minutes            <dbl> 0.00, 0.00, 0.28, 0.30, 0.00, 0.14, 0.25, 0~\n$ `G+A_Per_Minutes`          <dbl> 0.00, 1.29, 0.56, 0.89, 0.23, 0.77, 0.99, 1~\n$ G_minus_PK_Per_Minutes     <dbl> 0.00, 1.29, 0.28, 0.59, 0.23, 0.64, 0.62, 0~\n$ `G+A_minus_PK_Per_Minutes` <dbl> 0.00, 1.29, 0.56, 0.89, 0.23, 0.77, 0.87, 0~\n$ xG_Expected                <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ npxG_Expected              <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ xAG_Expected               <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ `npxG+xAG_Expected`        <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ xG_Per_Minutes             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ xAG_Per_Minutes            <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ `xG+xAG_Per_Minutes`       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ npxG_Per_Minutes           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n$ `npxG+xAG_Per_Minutes`     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,~\n\n\nLas 32 variables del dataset recojen las principales estadísticas del jugador por temporada y competencia. Cabrá destacar que las mismas son sólo de partidos de Liga y Champions League, no incorporando por ejemplo datos sobre la Copa del Rey, competición que Lio disputó y ganó durante su estadía en el Barcelona.\nCon los datos disponibles, creamos un cuadro que resume, por temporada, los goles, pases, asistencias y penales convertidos por Lio en la liga doméstica de España:\n\nmessi_stats%>%\n  filter(Squad==\"Barcelona\" & Comp== \"1. La Liga\")%>%\n  select(Season, MP, Gls, Ast, PK)%>%\n  rename(Temporada=Season,\n         Partidos=MP, \n         Goles=Gls, \n         Asistencias=Ast, \n         Penales=PK)%>%\n  gt()%>%\n  tab_header(title = \"Lionel Messi en Barcelona\",\n             subtitle = \"Estadisticas por temporada en La Liga 2004-2021\")\n\n\n\n\n\n  \n    \n      Lionel Messi en Barcelona\n    \n    \n      Estadisticas por temporada en La Liga 2004-2021\n    \n  \n  \n    \n      Temporada\n      Partidos\n      Goles\n      Asistencias\n      Penales\n    \n  \n  \n    2004-2005\n7\n1\n0\n0\n    2005-2006\n17\n6\n3\n0\n    2006-2007\n26\n14\n3\n0\n    2007-2008\n27\n10\n12\n4\n    2008-2009\n31\n23\n11\n3\n    2009-2010\n35\n34\n9\n1\n    2010-2011\n33\n31\n19\n4\n    2011-2012\n37\n50\n16\n10\n    2012-2013\n32\n46\n11\n4\n    2013-2014\n31\n28\n11\n7\n    2014-2015\n38\n43\n18\n5\n    2015-2016\n33\n26\n14\n3\n    2016-2017\n34\n37\n9\n6\n    2017-2018\n36\n34\n12\n2\n    2018-2019\n34\n36\n13\n4\n    2019-2020\n33\n25\n21\n5\n    2020-2021\n35\n30\n9\n3\n  \n  \n  \n\n\n\n\nUn punto destacable de este paquete es que podemos acceder a datos muy puntuales, como por ejemplo todas aquellas incidencias relacionadas con las oportunidades de tiro de un jugador o jugadora por campeonato y/o temporada. Veamos a continuación el ratio de goles convertidos por la cantidad de tiros al arco pateados por Messi jugando en la Champions Legue entre 2004 y 2022.\n\nmessi_tiros <- fb_player_season_stats(\"https://fbref.com/en/players/d70ce98e/Lionel-Messi\", stat_type = 'shooting')\n\n#write.xlsx(messi_tiros, 'messi_tiros.xlsx')\n\n\ntiroschampion<-messi_tiros%>%\n  filter(Comp==\"1. Champions Lg\")\n  \nggplot(tiroschampion) +\n  aes(x = Season, y = G_per_SoT_Standard) +\n  geom_col(fill = \"#A8B9D9\") +\n  labs(\n    x = \"Temporada\",\n    y = \"goles/tiros al arco\",\n    title = \"Lionel Messi en la Champions League 2004/2022\",\n    subtitle = \"Ratio de goles convertidos por disparos al arcos\",\n    caption= \"T&S en base a datos de fbref.com. Año 2022.\") +\n  geom_text(aes(label=G_per_SoT_Standard))+\n  theme(axis.text.x = element_text(angle = 35))\n\n\n\n\nResulta significativa la efectividad de Messi en la última temporada no?\nPara concluir el apartado de datos individuales, avanzaremos en la creación de una comparativa, requiriendo en simultáneo datos sobre los minutos jugados por Messi y Ronaldo en la temporada 2022-2023, considerando los partidos de liga y copa internacional (Champions o UEFA dependiendiendo el caso). Nos interesa saber cómo llegan ambos al mundial de Qatar en lo que respecta a ritmo futbolístico y tiempo en cancha.\n\n#pasamos la funcion fb_player_season_stats al vector de messi y ronaldo.\njugadores <- fb_player_season_stats(player_url = c(\"https://fbref.com/en/players/d70ce98e/Lionel-Messi\", \"https://fbref.com/en/players/dea698d9/Cristiano-Ronaldo\"), stat_type = \"playing_time\")#datos de tiempo de juego\n\n\n#openxlsx::write.xlsx(jugadores, 'jugadores.xlsx')\n\n\njugadores%>%\n  filter(Season==\"2022-2023\")%>%\n  group_by(player_name)%>%\n  summarise(partidos_tot=sum(MP), \n            min_tot= sum(Min_Time),\n            min_prom= min_tot/partidos_tot)%>%\n    mutate_if(is.numeric, round, digits=1)%>%\n  gt()\n\n\n\n\n\n  \n  \n    \n      player_name\n      partidos_tot\n      min_tot\n      min_prom\n    \n  \n  \n    Cristiano Ronaldo\n14\n875\n62.5\n    Lionel Messi\n17\n1486\n87.4\n  \n  \n  \n\n\n\n\nEn una primera vista, podríamos decir que en los últimos tiempos Messi jugó más que Ronaldo, participando de más partidos y siendo parte de los mismos durante más tiempo.\n\n\nLigas y partidos\nOtra posibilidad que nos brinda el paquete es recopilar, fecha a fecha, los partidos de una liga particular y sus incidencias.\nPongamos nuestra atención en último torneo argentino de primera división. Para ello vamos a recopilar mediante la funcion fb_match_urls los links de fbref con los datos de los partidos y vamos a guardarlos en el objeto primera_division.\nAl objeto primera división podremos pedirle campos detallados de estadísticas de goles, tiros al arco, pases, posesión y más. En este caso requeriremos un summary, o resumen, del torneo. Para ello utilizaremos la función fb_advanced_match_stats.\n\nfb_match_urls recopila los links cada partido en la base de fbstats\nprimera_division <- fb_match_urls(country = \"ARG\", #liga arg\n                               gender = \"M\", #masculino\n                               season_end_year = 2022, #temporada\n                               tier=\"1st\")\n\n# #recuperamos las estadisticas avanzadas\n\nprimera_resumen <- fb_advanced_match_stats(match_url = primera_division,\n                                                       stat_type = \"summary\",\n                                                       team_or_player = \"team\")\n\n\nglimpse(primera)\n\nRows: 754\nColumns: 38\n$ League            <chr> \"Argentine Primera División\", \"Argentine Primera Div~\n$ Match_Date        <chr> \"2022-06-03\", \"2022-06-03\", \"2022-06-04\", \"2022-06-0~\n$ Matchweek         <chr> \"Argentine Primera División (Matchweek 1)\", \"Argenti~\n$ Home_Team         <chr> \"Barracas Central\", \"Barracas Central\", \"Tucumán\", \"~\n$ Home_Formation    <chr> \"4-2-3-1\", \"4-2-3-1\", \"4-4-2\", \"4-4-2\", \"3-4-1-2\", \"~\n$ Home_Score        <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1~\n$ Home_xG           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~\n$ Home_Goals        <chr> \"Iván Tapia (P) · 13&rsquor;\", \"Iván Tapia (P) · 13&~\n$ Home_Yellow_Cards <chr> \"2\", \"2\", \"6\", \"6\", \"1\", \"1\", \"1\", \"1\", \"2\", \"2\", \"1~\n$ Home_Red_Cards    <chr> \"0\", \"0\", \"1\", \"1\", \"1\", \"1\", \"0\", \"0\", \"0\", \"0\", \"0~\n$ Away_Team         <chr> \"CC Córdoba\", \"CC Córdoba\", \"Colón\", \"Colón\", \"Indep~\n$ Away_Formation    <chr> \"4-4-2\", \"4-4-2\", \"4-5-1\", \"4-5-1\", \"4-2-3-1\", \"4-2-~\n$ Away_Score        <dbl> 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 0, 0, 1, 1~\n$ Away_xG           <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~\n$ Away_Goals        <chr> \"Renzo López · 77&rsquor;\", \"Renzo López · 77&rsquor~\n$ Away_Yellow_Cards <chr> \"5\", \"5\", \"4\", \"4\", \"2\", \"2\", \"3\", \"3\", \"2\", \"2\", \"2~\n$ Away_Red_Cards    <chr> \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0\", \"0~\n$ Game_URL          <chr> \"https://fbref.com/en/matches/fa531c8b/Barracas-Cent~\n$ Team              <chr> \"Barracas Central\", \"CC Córdoba\", \"Tucumán\", \"Colón\"~\n$ Home_Away         <chr> \"Home\", \"Away\", \"Home\", \"Away\", \"Home\", \"Away\", \"Hom~\n$ Min               <dbl> 990, 990, 983, 990, 984, 990, 990, 990, 990, 990, 99~\n$ Gls               <dbl> 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1~\n$ Ast               <dbl> 0, 1, 1, 0, 1, 1, 0, 2, 0, 1, 0, 1, 1, 2, 1, 0, 1, 1~\n$ PK                <dbl> 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0~\n$ PKatt             <dbl> 2, 0, 0, 1, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0~\n$ Sh                <dbl> 9, 12, 19, 7, 11, 17, 12, 11, 11, 15, 15, 9, 13, 10,~\n$ SoT               <dbl> 5, 6, 4, 3, 3, 4, 3, 3, 6, 3, 7, 5, 2, 4, 5, 2, 5, 6~\n$ CrdY              <dbl> 2, 5, 5, 4, 1, 2, 1, 3, 2, 2, 1, 2, 2, 2, 3, 4, 2, 3~\n$ CrdR              <dbl> 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0~\n$ Fls               <dbl> 12, 20, 13, 13, 11, 7, 6, 15, 12, 10, 20, 17, 13, 15~\n$ Fld               <dbl> 19, 10, 10, 13, 7, 11, 14, 5, 9, 12, 17, 20, 14, 11,~\n$ Off               <dbl> 1, 3, 1, 0, 1, 2, 1, 0, 3, 0, 0, 1, 3, 0, 0, 4, 1, 3~\n$ Crs               <dbl> 21, 19, 27, 15, 26, 17, 26, 19, 27, 15, 19, 19, 36, ~\n$ TklW              <dbl> 10, 20, 13, 8, 9, 11, 8, 12, 11, 18, 21, 12, 9, 16, ~\n$ Int               <dbl> 11, 16, 13, 5, 8, 5, 12, 13, 17, 8, 9, 10, 17, 6, 4,~\n$ OG                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0~\n$ PKwon             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~\n$ PKcon             <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~\n\n\nLa cantidad de datos que nos proveemos con el campo de consulta summary es significativa. Hagamos una transformación de nuestro conjunto de datos para establecer el resultado de los partidos jugados por el club Boca Juniors según la condición de local y visitante.\n\nboca<-primera%>%\n  filter(Team==\"Boca Juniors\")%>% #filtamos el equipo\n  select(Match_Date, Home_Team, \n         Away_Team, Home_Score, \n         Away_Score, Home_Away)%>%\n  mutate(puntos_obtenidos=case_when(Home_Away==\"Home\" & Home_Score>Away_Score ~3,\n                           Home_Away==\"Home\" & Home_Score<Away_Score~0,\n                           Home_Away==\"Away\" & Home_Score>Away_Score~0,\n                           Home_Away==\"Away\" & Home_Score<Away_Score~3,\n                           Home_Score==Away_Score~1))\n\nPodremos preguntarnos cuantos puntos sacó Boca en el último torneo?\n\n#si!\nboca%>%\n  summarise(puntos=sum(puntos_obtenidos))\n\n  puntos\n1     52\n\n\nY cual fue la performance de Boca de local y visitante?\n\n#Tambien!\nlibrary(janitor)\n\nboca %>%\n  tabyl(Home_Away, puntos_obtenidos)%>%\n  adorn_totals(\"row\") %>%\n  adorn_percentages(\"row\") %>%\n  adorn_pct_formatting() %>%\n  adorn_ns() %>%\n  adorn_title(\"combined\")\n\n Home_Away/puntos_obtenidos         0         1          3\n                       Away 38.5% (5)  7.7% (1) 53.8%  (7)\n                       Home 14.3% (2) 21.4% (3) 64.3%  (9)\n                      Total 25.9% (7) 14.8% (4) 59.3% (16)\n\n\nPodremos observar que el equipo sumó más puntos de local ganando más partidos y perdiendo menos que de visitante.\nPor último grafiquemos la progresión de puntos obtenidos fecha a fecha por el conjunto de la rivera durante el último torneo.\n\nboca<-boca%>%\n  mutate(cumsum = cumsum(puntos_obtenidos), #puntos acumulados\n         fecha=as.Date(Match_Date))\n\nboca%>%\n  ggplot() +\n  aes(x = fecha, y = cumsum) +\n  geom_point(shape = \"circle\", size = 1.7, colour = \"#4682B4\") +\n  geom_line(size = 0.5, colour = \"steelblue\") +\n    scale_x_date(date_labels = \"%b/%d\", \n                 date_breaks= \"week\")+\n  labs(\n    x = \"Semana\",\n    y = \"Puntaje\",\n    title = \"Boca Juniors: Progresión de puntos obtenidos en la liga 2022\",\n    subtitle = \"Primera División.\",\n    caption = \"Tecnología y Sociedad en base a datos de FBStats. Año 2022\"\n  ) +\n  ggthemes::theme_stata()+\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\nHistorial de Mundiales\nComo último elemento de nuestra exploración con R en el campo de las sports analytics, utilizaremos la función load_match_comp_results para recuperar en un dataframe los resultados históricos de los mundiales femeninos de fútbol.\n\nmundiales_w <- load_match_comp_results(comp_name = \"FIFA Women's World Cup\")\n\n#openxlsx::write.xlsx(mundiales_w, 'mundiales_w.xlsx') \n\n\ndplyr::glimpse(mundiales_w)\n\nRows: 284\nColumns: 20\n$ Competition_Name <chr> \"FIFA Women's World Cup\", \"FIFA Women's World Cup\", \"~\n$ Gender           <chr> \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\", \"F\"~\n$ Country          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ Season_End_Year  <dbl> 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991, 1991,~\n$ Round            <chr> \"Group stage\", \"Group stage\", \"Group stage\", \"Group s~\n$ Wk               <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ Day              <chr> \"Sat\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Sun\", \"Tue\", \"Tue~\n$ Date             <dbl> 33558, 33559, 33559, 33559, 33559, 33559, 33561, 3356~\n$ Time             <chr> \"20:45\", \"15:30\", \"19:45\", \"19:45\", \"19:45\", \"19:45\",~\n$ Home             <chr> \"China PR cn\", \"Germany de\", \"Japan jp\", \"Chinese Tai~\n$ HomeGoals        <dbl> 4, 4, 0, 0, 3, 2, 4, 1, 2, 0, 0, 0, 0, 0, 2, 4, 2, 0,~\n$ Home_xG          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ Away             <chr> \"no Norway\", \"ng Nigeria\", \"br Brazil\", \"it Italy\", \"~\n$ AwayGoals        <dbl> 0, 0, 1, 5, 0, 3, 0, 0, 2, 5, 8, 3, 3, 2, 0, 1, 1, 2,~\n$ Away_xG          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N~\n$ Attendance       <dbl> 65000, 14000, 14000, 11000, 14000, 14000, 12000, 1200~\n$ Venue            <chr> \"Tianhe Stadium (Neutral Site)\", \"Jiangmen Stadium (N~\n$ Referee          <chr> \"Salvador Imperatore Marcone\", \"Rafael Rodriguez\", \"L~\n$ Notes            <chr> \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"~\n$ MatchURL         <chr> \"https://fbref.com/en/matches/0d9e0f26/China-PR-Norwa~\n\n\nCuantos goles se anotaron en lo mundiales femeninos torneo a torneo? Cómo evolucionó la cantidad de asistentes por torneo?\n\nmundiales_tidy <- mundiales_w%>%\n  select(Season_End_Year, HomeGoals, AwayGoals, Attendance)%>%\n  mutate(goles=HomeGoals+AwayGoals)%>%\n  group_by(Season_End_Year)%>%\n  summarise(goles_total=sum(goles),\n            asistentes=sum(Attendance, na.rm = TRUE))%>%\n  mutate(fecha=as.factor(Season_End_Year))%>%\n  select(!Season_End_Year)\n\nmundiales_tidy%>%\n  gt()\n\n\n\n\n\n  \n  \n    \n      goles_total\n      asistentes\n      fecha\n    \n  \n  \n    99\n515000\n1991\n    99\n112294\n1995\n    122\n1214215\n1999\n    105\n656789\n2003\n    111\n1176955\n2007\n    86\n248107\n2011\n    146\n1353486\n2015\n    146\n1095118\n2019\n  \n  \n  \n\n\n\n\nGrafiquemos nuestros resultados, vamos usar el eje Y para dar cuenta del público, y en un eje Y secundario para imprimir los datos de los goles.\n\nmundiales_tidy%>%\n  ungroup()%>%\n  ggplot() +\n  geom_bar(aes(x=fecha, y=asistentes), \n           stat=\"identity\", fill=\"#9BCD9B\", alpha=0.7, group = 1)+\n  geom_line(aes(x=fecha, y=goles_total*10000), size=1.2,\n            stat=\"identity\", color=\"#278AFC\", group = 2)+\n  geom_point(aes(x=fecha, y=goles_total*10000), size=2,\n            stat=\"identity\", color=\"#0364D4\", alpha=0.5 ,group = 2)+\n  labs(title= \"Espectadores y Goles por Mundial Femenino disputado\",\n       subtitle = \"Período 1991-2019.\",\n       x=\"Torneo\",\n       y=\"Espectadores\",\n       caption = \"T&S en base a datos de fbref.com. Año 2022.\")+\n  scale_y_continuous(sec.axis=sec_axis(~.*0.0001,\n                                       name=\"Goles\"))"
  },
  {
    "objectID": "posts/sport/index.html#conclusiones",
    "href": "posts/sport/index.html#conclusiones",
    "title": "Sports Analytics con R: explorando datos de Fútbol",
    "section": "Conclusiones",
    "text": "Conclusiones\nA lo largo de esta experiencia pudimos adentrarnos la múltiples posibilidades que nos brinda R para recopilar y explorar datos de fútbol utilizando el paquete worldfootballR. Llevando adelante técnicas EDA y de análisis descriptivo pudimos respondernos algunas preguntas sistematizando distintos conjuntos de datos descargados en cápsulas de información relevante, la materia prima que alimenta los procesos de analítica descriptiva.\nSerá destacable mencionar que este tipo de experiencias aplicadas no sólo son últiles para el análisis de procesos deportivos en sí, sino que además pueden volver mas cercanos aprendizajes relativos al procesamiento e indagación con datos, ya que se trata de técnicas amenas que constelan con abordajes de realidades gamificadas y cercanas, al ser por ejemplo el fútbol un deporte de gran impacto popular.\nEn suma, las sports analytics hoy son una realidad en el mundo del análisis y ciencia de datos, pueden ser una interesante puerta de entrada para quienes se están iniciando o una profesión rentable para los analistas profesionales…un momento…y el Mundial de Qatar 2022?\nContinuará."
  },
  {
    "objectID": "posts/sport/index.html#bibliografía-consultada",
    "href": "posts/sport/index.html#bibliografía-consultada",
    "title": "Sports Analytics con R: explorando datos de Fútbol",
    "section": "Bibliografía consultada:",
    "text": "Bibliografía consultada:\nExtracting data from FBref : https://jaseziv.github.io/worldfootballR/articles/extract-fbref-data.html\nFootball Analytics: Creating an xG-xGA comparison chart in R : https://www.invertedwinger.com/football-analytics-creating-an-xg-xga-comparison-chart-in-r/\nSport Analytics: A Review: https://www.academia.edu/73063599/Sport_Analytics_A_Review\nBig data and tactical analysis in elite soccer: future challenges and opportunities for sports science. https://springerplus.springeropen.com/articles/10.1186/s40064-016-3108-2"
  }
]